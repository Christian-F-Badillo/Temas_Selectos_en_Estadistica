---
title: "Estadística Descriptiva"
subtitle: "Visualización de Datos y Teoremas Importantes"
author: "Christian F. Badillo Hernández"
date: 01/08/24
lang: "es"
date-format: "D MMM YYYY"
format:
    revealjs:
        incremental: true
        scrollable: true
        smaller: false   
        theme: night
        logo: img/Lab25_logo_2015.png
        footer: "Temas Selectos en Estadística"
        preview-links: true
        preload-iframes: true
        slide-number: true
        transition: convex
        background-transition: fade
        transition-speed: slow
        navigation-mode: linear
        touch: true
        controls: true
        embed-resources: true
        page-layout: custom
        reference-location: document
        link-external-newwindow: true
        fig-height: 7
        fig-responsive: true
engine: knirt
server: shiny
runtime: shiny
---

# Momentos

> "The death of a men is a tragedy, the death of millions is a statistic." - Joseph Stalin

## Definición {.smaller}

* Todas las distribuciones de probabilidad tienen un conjunto de características (parámetros) que las describen. Estas características se conocen como **momentos**.

* Normalmente se suelen presentar como **medidas de tendencia central** y **medidas de dispersión**. Pero el concepto de momento es más general.

* Cada momento estadístico se puede calcular utilizando la **función generadora de momentos**, que se define para cada distribución de probabilidad. 

* Debido a que su uso requiere mayor conocimiento de cálculo, no se abordará en este curso. Pero se presentaran los momentos más comunes de la forma habitual.

* Quien desee profundizar en el tema puede consultar la sección $4.4$ del libro ***["Probability and Statistics"](http://www.economia.unam.mx/biblioteca/Pdf/Morris%20H%20DeGroot_%20Mark%20J%20Schervish-Probability%20and%20statistics-Pearson%20Education%20%20(2012).pdf)*** de **Morris H. DeGroot**.

## Valor Esperado {.smaller}

* El ***valor esperado*** (esperanza matemática, media) de una v.a discreta $X$ se define como:
$$
E(X) = \mu = \sum_{i=1}^n x_i p_i
$$

* El ***valor esperado*** (esperanza matemática, media) de una v.a continua $X$ se define como:
$$
E(X) = \mu = \int_{-\infty}^{\infty} x f(x) dx
$$

* El valor esperado es una medida de tendencia central. Y nos dice el valor promedio que se espera obtener de una v.a. y es la mejor estimación de la v.a. en el largo plazo.

* En ambos casos ponderamos cada valor de la v.a. por su probabilidad de ocurrencia.

* El valor esperado también se puede interpretar como el centro de gravedad de la distribución de probabilidad y define al *primer momento* de la distribución.

## Valor Esperado Muestral {.smaller}

* Cuando se realiza un muestreo de una población, se puede estimar el valor esperado de la población con el valor esperado muestral, que se define como:
$$
\bar{x} = \frac{\sum_{i=1}^n x_i}{n}
$$

* Al ser una estimación, el valor esperado muestral no es igual al valor esperado de la población, sin embargo, conforme el tamaño de la muestra aumenta, el valor esperado muestral se acerca al valor esperado de la población (recuerden la interpretación frecuentista de la probabilidad).

## Ejemplo 1: Valor Esperado {.smaller}

* Supongamos que tenemos una v.a. discreta $X$ con la siguiente función de probabilidad:
$$
\begin{array}{c|c|c|c|c}
x_i & 1 & 2 & 3 & 4 \\ \hline
p_i & 0.1 & 0.2 & 0.3 & 0.4
\end{array}
$$

* Entonces el valor esperado de $X$ es:
$$
\begin{align*}
E(X) &= \mu = \sum_{i=1}^n x_i p_i = \\
&1(0.1) + 2(0.2) + 3(0.3) + 4(0.4) \\
&= 3
\end{align*}
$$

* Es decir, en promedio se espera obtener $3$ unidades de $X$.

## Ejemplo 2: Valor Esperado {.smaller}

* Si tenemos un dado de $6$ caras, entonces la v.a. $X$ que representa el resultado de lanzar el dado tiene la siguiente función de probabilidad:
$$
\begin{array}{c|c|c|c|c|c|c}
x_i & 1 & 2 & 3 & 4 & 5 & 6 \\ \hline
p_i & \frac{1}{6} & \frac{1}{6} & \frac{1}{6} & \frac{1}{6} & \frac{1}{6} & \frac{1}{6}
\end{array}
$$

* ¿Cuál es el valor esperado de $X$?

* Respuesta:
$$
\begin{align*}
E(X) &= \mu = \sum_{i=1}^n x_i p_i \\
&= 1\left(\frac{1}{6}\right) + 2\left(\frac{1}{6}\right) + 3\left(\frac{1}{6}\right) \\
&+ 4\left(\frac{1}{6}\right) + 5\left(\frac{1}{6}\right) + 6\left(\frac{1}{6}\right) \\
&= \frac{21}{6} = 3.5
\end{align*}
$$

## Ejemplo 3: Valor Esperado {.smaller}

* Si tenemos una v.a. bernoulli $X$ con $p = 0.3$, entonces su función de probabilidad es:
$$
\begin{array}{c|c|c}
x_i & 0 & 1 \\ \hline
p_i & 0.7 & 0.3
\end{array}
$$

* ¿Cuál es el valor esperado de $X$?

* Respuesta:
$$
\begin{align*}
E(X) &= \mu = \sum_{i=1}^n x_i p_i \\
&= 0(0.7) + 1(0.3) \\
&= 0.3
\end{align*}
$$

* En general, si tenemos una v.a. bernoulli $X$ con $p$, entonces su valor esperado es:
$$
E(X) = \mu = p
$$

## Ejemplo 4: Valor Esperado {.smaller}

* Si tenemos una v.a. uniforme continua $X$ con $a = 0$ y $b = 10$, entonces su función de densidad es:
$$
f(x) = \frac{1}{10 - 0} = \frac{1}{10}
$$

* Su valor esperado se calcula como:
$$
\begin{align*}
E(X) &= \mu = \int_{-\infty}^{\infty} x f(x) dx \\
&= \int_{0}^{10} x \frac{1}{10} dx \\
&= \frac{1}{10} \int_{0}^{10} x dx \\
&= \frac{1}{10} \left[\frac{x^2}{2}\right]_0^{10} \\
&= \frac{1}{10} \left[\frac{10^2}{2} - \frac{0^2}{2}\right] \\
&= \frac{100}{20} = 5
\end{align*}
$$

* En general, si tenemos una v.a. uniforme continua $X$ con $a$ y $b$, entonces su valor esperado es:
$$
E(X) = \mu = \frac{a + b}{2}
$$

## Ejemplo 5: Valor Esperado {.smaller}

* Si tenemos una v.a. exponencial $X$ con $\lambda = 0.5$, entonces su función de densidad es:
$$
f(x) = \lambda e^{-\lambda x} = 0.5 e^{-0.5 x}
$$

* Su valor esperado es:
$$
\begin{align*}
E(X) &= \mu = \int_{-\infty}^{\infty} x f(x) dx \\
&= \int_{0}^{\infty} x 0.5 e^{-0.5 x} dx \\
&= 0.5 \int_{0}^{\infty} x e^{-0.5 x} dx \\
&= 0.5 \left[-2 e^{-0.5 x} (x + 2)\right]_0^{\infty} \\
&= 0.5 \left[-2 e^{-0.5 \infty} (\infty + 2) - (-2 e^{-0.5 0} (0 + 2))\right] \\
&= 0.5 \left[-2 (0) (\infty + 2) - (-2 (1) (0 + 2))\right] \\
&= 0.5 \left[0 - (-2 (1) (2))\right] \\
&= 0.5 \left[4\right] \\
&= 2
\end{align*}
$$

En general, si tenemos una v.a. exponencial $X$ con $\lambda$, entonces su valor esperado es:
$$
E(X) = \mu = \frac{1}{\lambda}
$$

##

| Distribución | Valor esperado |
|:------------:|:--------------:|
| Bernoulli | $p$ |
| Binomial | $np$ |
| Geométrica | $\frac{1}{p}$ |
| Poisson | $\lambda$ |
| Uniforme discreta | $\frac{a + b}{2}$ |
| Uniforme continua | $\frac{a + b}{2}$ |
| Exponencial | $\frac{1}{\lambda}$ |
| Normal | $\mu$ |
| Normal estándar | $0$ |
| Log-normal | $e^{\mu + \frac{\sigma^2}{2}}$ |
| Chi-cuadrada | $k$ |
| Beta | $\frac{\alpha}{\alpha + \beta}$ |
| T de Student | $0$ |
| F de Fisher-Snedecor | $\frac{\nu_2}{\nu_2 - 2}$ |
| Gamma | $\frac{\alpha}{\lambda}$ |

## Varianza {.smaller}

* La ***variabilidad*** de una v.a. $X$ se mide con la ***varianza***, que se define como:
$$
Var(X) = \sigma^2 = E\left[(X - \mu)^2\right]
$$

* Representa el promedio de la distancia al cuadrado de cada valor de la v.a. con respecto a su valor esperado. En otras palabras, mide la dispersión de los valores de la v.a. con respecto a la media.

* La varianza pertenece a los ***momentos centrales*** de la distribución. Estos se definen como:
$$
\mu_k = E\left[(X - \mu)^k\right]
$$

* El primer momento central es la varianza.

## Desviación Estándar {.smaller}

* La ***desviación estándar*** de una v.a. $X$ se define como:
$$
\sigma = \sqrt{Var(X)} = \sqrt{\sigma^2} = \sqrt{E\left[(X - \mu)^2\right]}
$$

* Es la raíz cuadrada de la varianza y representa la distancia promedio de cada valor de la v.a. con respecto a su valor esperado en su misma unidad de medida.

* La desviación estándar es más fácil de interpretar que la varianza, pero es menos útil para realizar cálculos, muchos modelos estadísticos requieren la varianza.

## Ejemplo 1: Varianza {.smaller}

* Supongamos que tenemos una v.a. discreta $X$ con la siguiente función de probabilidad:
$$
\begin{array}{c|c|c|c|c}
x_i & 1 & 2 & 3 & 4 \\ \hline
p_i & 0.1 & 0.2 & 0.3 & 0.4
\end{array}
$$

* Anteriormente calculamos que el valor esperado de $X$ es $3$. Entonces la varianza de $X$ es:
$$
\begin{align*}
Var(X) &= \sigma^2 = E\left[(X - \mu)^2\right] \\
&= E\left[(X - 3)^2\right] \\
&= \sum_{i=1}^n (x_i - 3)^2 p_i \\
&= (1 - 3)^2(0.1) + (2 - 3)^2(0.2) \\
&+ (3 - 3)^2(0.3) + (4 - 3)^2(0.4) \\
&= 0.1 + 0.2 + 0.4 \\
&= 0.7
\end{align*}
$$

* Y la varianza estándar de $X$ es:
$$
\sigma = \sqrt{Var(X)} = \sqrt{0.7} = 0.8367
$$

## Varianza muestral {.smaller}

* Cuando no se conoce la función de probabilidad de una v.a. discreta $X$, se puede estimar la varianza de la siguiente forma:
$$
\begin{align*}
Var(X) &= \sigma^2 = E\left[(X - \mu)^2\right] \\
&= \frac{\sum_{i=1}^n (x_i - \mu)^2}{n-1}
\end{align*}
$$

* Es decir, se calcula el valor esperado de la v.a. utilizando el segundo método y se divide entre $n-1$, donde $n$ es el número de observaciones. Esta varianza se conoce como ***varianza muestral***.

* El factor $n-1$ se conoce como ***grados de libertad*** y se utiliza para corregir el sesgo de la estimación.

* La varianza muestral es un estimador insesgado de la varianza poblacional. Es decir, en promedio la varianza muestral es igual a la varianza poblacional.

##

```{r}
#| panel: input
sliderInput("n", "Número de observaciones:", min = 2, max = 150, value = 2, step = 1)
```

```{r}
```

```{r}
#| context: server
library(ggplot2)
library(ggdark)
output$var <- renderPlot({
    n <- input$n
    set.seed(1234)
    samples <- rnorm(n)
    x <- seq(-6, 6, 0.01)

    sample_var_unbias <- sum((samples - mean(samples))^2) / (n - 1)
    
    df <- data.frame(x = x, y = dnorm(x))
    df2 <- data.frame(x = samples, y = rep(0, n))

    ggplot(df, aes(x = x, y = y)) +
        geom_line(color = "white") +
        geom_point(data = df2, aes(x = x, y = y), color = "white", size = 6) +

        geom_vline(xintercept = mean(samples), color = "red", linetype = "dashed") +
        geom_vline(xintercept = mean(samples) + sqrt(sample_var_unbias), color = "green", linetype = "dashed") +
        geom_vline(xintercept = mean(samples) - sqrt(sample_var_unbias), color = "green", linetype = "dashed") +
        geom_vline(xintercept = 0, color = "white") +
        geom_vline(xintercept = 1, color = "white") +

        geom_text(aes(x = mean(samples) - sqrt(sample_var_unbias), 
        y = 0.25, label = "\u03C3 Muestral"), 
        color = "green", size = 8) +
        geom_text(aes(x = mean(samples), 
        y = 0.35, label = "\u03BC Muestral"), 
        color = "pink", size = 8) +

        scale_x_continuous(breaks = seq(-6, 6, 1)) +
        dark_theme_gray() +
        labs(x = "x", y = "f(x)") +
        theme(axis.text = element_text(size = 30),
            axis.title = element_text(size = 40),
            plot.title = element_text(size = 50))
})

```

```{r}
#| panel: fill  
plotOutput("var", width = "100%", height = "590px")
```

## Ejemplo 2: Varianza muestral {.smaller}

* Imaginemos que realiza una encuesta a $10$ personas y les pregunta su edad. Los resultados son los siguientes:
$$
\begin{array}{c|c|c|c|c|c|c|c|c|c|c}
x_i & 18 & 19 & 20 & 21 & 22 & 23 & 24 & 25 & 26 & 27 \\ \hline
\end{array}
$$

* ¿Cuál es la varianza muestral de la edad de las personas encuestadas?

* Respuesta:
$$
\begin{align*}
Var(X) &= \sigma^2 = E\left[(X - \mu)^2\right] \\
&= \frac{\sum_{i=1}^n (x_i - \mu)^2}{n-1} \\
&= \frac{(18 - 22)^2 + (19 - 22)^2 + (20 - 22)^2}{9} \\
&+ \frac{(21 - 22)^2 + (22 - 22)^2}{9} \\
&+ \frac{(23 - 22)^2 + (24 - 22)^2 + (25 - 22)^2}{9} \\
&+ \frac{(26 - 22)^2 + (27 - 22)^2}{9} \\
&= \frac{16 + 9 + 4 + 1 + 0 + 1 + 4 + 9 + 16 + 25}{9} \\
&= \frac{85}{9} = 9.4444
\end{align*}
$$

## Ejemplo 3: Varianza muestral {.smaller}

* Si tenemos una v.a. bernoulli $X$ con $p = 0.3$.
$$
\begin{array}{c|c|c}
x_i & 0 & 1 \\ \hline
p_i & 0.7 & 0.3
\end{array}
$$

* ¿Cuál es la varianza de $X$?

* Respuesta:
$$
\begin{align*}
Var(X) &= \sigma^2 = E\left[(X - \mu)^2\right] \\
&= E\left[(X - 0.3)^2\right] \\
&= (0 - 0.3)^2(0.7) + (1 - 0.3)^2(0.3) \\
&= 0.063 + 0.147 \\
&= 0.21
\end{align*}
$$

* Su desviación estándar es: $\sigma = \sqrt{0.21} = 0.4583$

* En general, si tenemos una v.a. bernoulli $X$ con $p$, entonces su varianza es:
$$
Var(X) = \sigma^2 = p(1 - p)
$$

## Ejemplo 4: Varianza muestral {.smaller}

* Si tenemos una v.a. uniforme continua $X$ con $a = 0$ y $b = 10$, entonces:
$$
f(x) = \frac{1}{10 - 0} = \frac{1}{10}
$$

* Su varianza se calcula como:
$$
\begin{align*}
Var(X) &= \sigma^2 = E\left[(X - \mu)^2\right] \\
&= \int_{-\infty}^{\infty} (x - \mu)^2 f(x) dx \\
&= \int_{0}^{10} (x - 5)^2 \frac{1}{10} dx \\
&= \frac{1}{10} \int_{0}^{10} (x - 5)^2 dx \\
&= \frac{1}{10} \left[\frac{(x - 5)^3}{3}\right]_0^{10} \\
&= \frac{1}{10} \left[\frac{(10 - 5)^3}{3} - \frac{(0 - 5)^3}{3}\right] \\
&= \frac{1}{10} \left[\frac{125}{3} - \frac{-125}{3}\right] \\
&= \frac{1}{10} \left[\frac{250}{3}\right] \\
&= \frac{25}{3} = 8.3333
\end{align*}
$$

* Y su desviación estándar es: $\sigma = \sqrt{8.3333} = 2.8868$

* En general, si tenemos una v.a. uniforme continua $X$ con $a$ y $b$, entonces su varianza es:
$$
Var(X) = \sigma^2 = \frac{(b - a)^2}{12}
$$

##

| Distribución | Varianza |
|:------------:|:--------------:|
| Bernoulli | $p(1 - p)$ |
| Binomial | $np(1 - p)$ |
| Geométrica | $\frac{1 - p}{p^2}$ |
| Poisson | $\lambda$ |
| Uniforme discreta | $\frac{n^2 - 1}{12}$ |
| Uniforme continua | $\frac{(b - a)^2}{12}$ |
| Exponencial | $\frac{1}{\lambda^2}$ |
| Normal | $\sigma^2$ |
| Normal estándar | $1$ |
| Log-normal | $e^{2\mu + \sigma^2}(e^{\sigma^2} - 1)$ |
| Chi-cuadrada | $2k$ |
| Beta | $\frac{\alpha \beta}{(\alpha + \beta)^2 (\alpha + \beta + 1)}$ |
| T de Student | $\frac{\nu_2}{\nu_2 - 2}$ |
| F de Fisher-Snedecor | $\frac{2\nu_2^2(\nu_1 + \nu_2 - 2)}{\nu_1(\nu_2 - 2)^2(\nu_2 - 4)}$ |
| Gamma | $\frac{\alpha}{\lambda^2}$ |

## Mediana {.smaller}

* La ***mediana*** de una v.a. $X$ se define como el valor que divide a la distribución en dos partes iguales. Es decir, el $50\%$ de los valores de la v.a. son menores o iguales a la mediana y el otro $50\%$ son mayores o iguales a la mediana.

* La mediana es una medida de tendencia central. Y es una medida de tendencia central más robusta que el valor esperado, ya que no se ve afectada por valores atípicos.

* No se considera un momento estadístico, ya que no se puede calcular utilizando la función generadora de momentos.

* La mediana se puede calcular de la siguiente forma una vez que se tienen los valores de la v.a. ordenados de menor a mayor:
$$
\begin{align*}
Mediana(X) &= \begin{cases}
x_{\frac{n+1}{2}} & \text{si } n \text{ es impar} \\
\frac{x_{\frac{n}{2}} + x_{\frac{n}{2} + 1}}{2} & \text{si } n \text{ es par}
\end{cases}
\end{align*}
$$

## Ejemplo 1: Mediana {.smaller}

* Tenemos el resultado de una encuesta a $10$ personas sobre su edad:
$$
\begin{array}{c|c|c|c|c|c|c|c|c|c|c}
x_i & 18 & 19 & 20 & 21 & 22 & 23 & 24 & 25 & 26 & 27 \\ \hline
\end{array}
$$

* ¿Cuál es la mediana de la edad de las personas encuestadas?

* Respuesta:
$$
\begin{align*}
Mediana(X) &= \frac{x_{\frac{n}{2}} + x_{\frac{n}{2} + 1}}{2} \\
&= \frac{x_{\frac{10}{2}} + x_{\frac{10}{2} + 1}}{2} \\
&= \frac{x_{5} + x_{6}}{2} \\
&= \frac{22 + 23}{2} \\
&= 22.5
\end{align*}
$$

## Ejemplo 2: Mediana {.smaller}

* Tenemos los datos de 7 personas acerca de su ingreso mensual:
$$
\begin{array}{c|c|c|c|c|c|c|c}
x_i & 11729 & 9831 & 7560 & 20454 & 12000 & 10200 & 15000 \\ \hline
\end{array}
$$

* ¿Cuál es la mediana del ingreso mensual de las personas encuestadas?

* Respuesta:
$$
\begin{align*}
Mediana(X) &= x_{\frac{n+1}{2}} \\
&= x_{\frac{7+1}{2}} \\
&= x_{4} \\
&= 11729
\end{align*}
$$

## Moda {.smaller}

* La ***moda*** de una v.a. $X$ se define como el valor que tiene la mayor probabilidad de ocurrencia. Es decir, el valor que más se repite.

* Existen distribuciones con más de una moda, a estas se les conoce como ***distribuciones multimodales***. Por ejemplo, la distribución normal tiene una sola moda, pero la distribución uniforme continua tiene infinitas modas.

* La moda es una medida de tendencia central. Y es una medida de tendencia central más robusta que el valor esperado, ya que no se ve afectada por valores atípicos. Pero es menos robusta que la mediana.

* Tampoco es un momento estadístico.

## Ejemplo 1: Moda {.smaller}

* Tenemos el resultado de una encuesta a $10$ personas sobre su edad:
$$
\begin{array}{c|c|c|c|c|c|c|c|c|c|c}
x_i & 29 & 19 & 20 & 22 & 22 & 23 & 24 & 25 & 26 & 27 \\ \hline
\end{array}
$$

* ¿Cuál es la moda de la edad de las personas encuestadas?

* Respuesta: $22$

## Ejemplo 2: Moda {.smaller}

* Los semestres de los alumnos de la clase son:
$$
\begin{align*}
&3, 3, 3, 5, 3, 1, 3, 1, 5, 5, \\
&3, 5, 5, 5, 5, 3, 3, 7, 7, 3,  \\
&5, 3, 7, 5, 7, 7, 5, 5, 3
\end{align*}
$$

* ¿Cuál es la moda de los semestres de los alumnos?

* Respuesta: $3$ y $5$

## Sesgo {.smaller}

* El ***sesgo*** de una v.a. $X$ se define como:
$$
\gamma_1 = E\left[\left(\frac{X - \mu}{\sigma}\right)^3\right]
$$

* Es una medida de asimetría de la distribución de probabilidad. Si la distribución es simétrica, entonces el sesgo es $0$. Si la distribución es asimétrica a la derecha, entonces el sesgo es positivo. Si la distribución es asimétrica a la izquierda, entonces el sesgo es negativo.

* Nos indica la dirección en la que se encuentra la cola de la distribución con respecto a la media.

* El sesgo es un momento estadístico en específico es el ***tercer momento central***

## Kurtosis {.smaller}

* La ***kurtosis*** de una v.a. $X$ se define como:
$$
\gamma_2 = E\left[\left(\frac{X - \mu}{\sigma}\right)^4\right]
$$

* Es una medida de la forma de la distribución de probabilidad. Si la distribución es normal, entonces la kurtosis es $3$. Si la distribución es más puntiaguda que la normal, entonces la kurtosis es mayor a $3$. Si la distribución es más achatada que la normal, entonces la kurtosis es menor a $3$.

* Es el momento estadístico de orden $4$.


## Ejemplo: Sesgo y Curtosis {.smaller}

::: {.panel-tabset}

## Datos
::: {.nonincremental}
* Tenemos los datos de distintos vehículos de 1973-1974, los cuales se pueden encontrar en el conjunto de datos `mtcars` de `R`:
:::
```{r table1, tidy=FALSE, echo=FALSE}
knitr::kable(
  mtcars[,], booktabs = TRUE,
  caption = 'Tabla 1.'
)
```

## Histograma
::: {.nonincremental}

* Un histograma es un método gráfico para representar la distribución de frecuencias de una v.a. discreta o continua.

* Se divide el rango de la v.a. en intervalos de igual tamaño y se cuenta el número de observaciones que caen en cada intervalo. Por lo general se utilizan intervalos de igual tamaño, pero no es necesario.

* El histograma se puede utilizar para identificar la forma de la distribución de la v.a. y para identificar valores atípicos. Y se pude utilizar para estimar la función de densidad de la v.a.

* Debido a lo complicado de calcular el sesgo de los datos, se puede utilizar el histograma para identificar la asimetría de la distribución.
:::

```{r hist1, echo=FALSE, fig.align='center'}
library(ggplot2)
library(ggdark)

ggplot(mtcars, aes(x = mpg)) +
  geom_histogram(binwidth = 2, fill = "blue", color = "black") +
  dark_theme_gray() +
  labs(x = "Millas por galón", y = "Frecuencia") +
  theme(axis.text = element_text(size = 30),
        axis.title = element_text(size = 40),
        plot.title = element_text(size = 50))
```

## Sesgo y Curtosis

::: {.nonincremental}
* Una distribución sesgada positivamente tiene la cola a la derecha de la media. Y una distribución sesgada negativamente tiene la cola a la izquierda de la media. Por tanto nuestro histograma nos indica que la distribución de la v.a. `mpg` es sesgada positivamente.

```{r, echo=FALSE, fig.align='center'}
library(ggplot2)
library(ggdark)

ggplot(mtcars, aes(x = mpg)) +
  geom_histogram(binwidth = 2, fill = "blue", color = "black") +
  geom_vline(xintercept = mean(mtcars$mpg), color = "red", linetype = "dashed", size = 4) +
  dark_theme_gray() +
  labs(x = "Millas por galón", y = "Frecuencia") +
  theme(axis.text = element_text(size = 30),
        axis.title = element_text(size = 40),
        plot.title = element_text(size = 50))
```

* Esto se puede confirmar utilizando la función `skewness` del paquete `moments` de `R`:

```{r echo=TRUE}
install.packages("moments")
library(moments)
skewness(mtcars$mpg)
```

* La curtosis indica que tan puntiaguda o plana es la distribución con respecto a la normal, en nuestro histograma podemos ver que la distribución es más plana que la normal.

```{r, echo=FALSE, fig.align='center'}
library(ggplot2)
library(ggdark)
x <- seq(min(mtcars$mpg), max(mtcars$mpg), 0.01)
y <- dnorm(x, mean(mtcars$mpg), sd(mtcars$mpg))


ggplot() +
  geom_histogram(aes(x = mtcars$mpg, y = after_stat(density)), binwidth = 2, fill = "blue", color = "black") +
  geom_density(aes(x = mtcars$mpg), fill = "green", alpha = 0.5) +
  geom_line(aes(x = x, y = y), color = "white", size = 6) +
  geom_vline(xintercept = mean(mtcars$mpg), color = "red", linetype = "dashed", size = 4) +
  dark_theme_gray() +
  labs(x = "Millas por galón", y = "Densidad") +
  theme(axis.text = element_text(size = 30),
        axis.title = element_text(size = 40),
        plot.title = element_text(size = 50))
```


* Podemos calcular la curtosis de la v.a. `mpg` utilizando la función `kurtosis` del paquete `moments` de `R`:

```{r echo=TRUE}
library(moments)
kurtosis(mtcars$mpg)
```

* Al ser menor que 3 podemos concluir que la distribución de la v.a. `mpg` es más aplanada que la distribución normal.

:::

:::

## Rango

* El ***rango*** de una v.a. $X$ se define como:
$$
R = x_{max} - x_{min}
$$

* Es una medida de dispersión. Y nos indica la distancia entre el valor máximo y el valor mínimo de la v.a.

* No es un momento estadístico.

## Ejemplo: Rango {.smaller}
::: {.nonincremental}
* Siguiendo con los datos de los vehículos de 1973-1974, tenemos que el rango de la v.a. `mpg` es:

```{r echo=TRUE}
max(mtcars$mpg) - min(mtcars$mpg)
```
:::

* Si tenemos una v.a. uniforme continua $X$ con $a$ y $b$, entonces su rango es:
$$
R = b - a
$$

## Percentiles y Cuartiles {.smaller}

* Los ***percentiles*** de una v.a. $X$ se definen como las $100$ partes iguales en las que se divide la distribución de probabilidad de la v.a. al ordenar los valores de menor a mayor.

* El ***percentil $p$*** de una v.a. $X$ se define como el valor que divide a la distribución en $p$ partes iguales. Es decir, el $p\%$ de los valores de la v.a. son menores o iguales al percentil $p$ y el otro $100 - p\%$ son mayores o iguales al percentil $p$.

* Los ***cuartiles*** son los percentiles $25$, $50$ y $75$. Y los ***deciles*** son los percentiles $10$, $20$, $30$, $40$, $50$, $60$, $70$, $80$ y $90$. Sirven para dividir la distribución en $4$ y $10$ partes iguales respectivamente.

* El percentil $50$ se conoce como ***mediana***.

* El ***rango intercuartil*** se define como:
$$
IQR = Q_3 - Q_1
$$

* Es una medida de dispersión. Y nos indica la distancia entre el tercer cuartil y el primer cuartil de la v.a.

## Ejemplo: Percentiles y Cuartiles {.smaller}

::: {.panel-tabset}

## Datos
::: {.nonincremental}
* Ahora usemos los datos de la longitud de los pétalos de la flor de iris, los cuales se pueden encontrar en el conjunto de datos `iris` de `R`:
```{r table2, tidy=FALSE, echo=FALSE}
knitr::kable(
  iris[,], booktabs = TRUE,
  caption = 'Tabla 2.'
)
```
:::

## Diagrama de caja y bigotes

::: {.nonincremental}

* Un diagrama de caja y bigotes es un método gráfico para representar la distribución de frecuencias de una v.a. discreta o continua.

* En este diagrama se representa el rango intercuartil, los cuartiles, la mediana y los valores atípicos.   

* Los bordes de la caja representan el primer y tercer cuartil. La línea que divide la caja representa la mediana. Lo alto de la caja representa el rango intercuartil. 

* Las líneas que salen de la caja se conocen como bigotes. Y los valores que se encuentran fuera de los bigotes se conocen como valores atípicos. Los bigotes se calculan de la siguiente forma:
$$
\begin{align*}
Bigote\ inferior &= Q_1 - 1.5 \times IQR \\
Bigote\ superior &= Q_3 + 1.5 \times IQR
\end{align*}
$$

```{r boxplot1, echo=FALSE, fig.align='center'}
library(ggplot2)
library(ggdark)

ggplot(iris, aes(x = Species, y = Petal.Length)) +
  geom_boxplot(fill = "blue", outlier.color = "red", outlier.size = 6, color = "white") +
  dark_theme_gray() +
  labs(x = "Especie", y = "Longitud del pétalo") +
  theme(axis.text = element_text(size = 30),
        axis.title = element_text(size = 40),
        plot.title = element_text(size = 50))
```

:::

## Diagrama de Violín

::: {.nonincremental}

* Un diagrama de violín es muy similar a un diagrama de caja y bigotes. La diferencia es que en lugar de representar la caja y los bigotes, se representa la función de densidad de la v.a. en cada categoría.

```{r violin1, echo=FALSE, fig.align='center'}
library(ggplot2)
library(ggdark)

ggplot(iris, aes(x = Species, y = Petal.Length)) +
  geom_violin(fill = "blue", color = "white") +
  dark_theme_gray() +
  labs(x = "Especie", y = "Longitud del pétalo") +
  theme(axis.text = element_text(size = 30),
        axis.title = element_text(size = 40),
        plot.title = element_text(size = 50))
```

* Sin embargo, las fortalesas de los diagramas de violín son sus debilidades. Ya que al representar la función de densidad, se pierde la información de los cuartiles, la mediana y los valores atípicos. Una solución es combinar los diagramas de caja y bigotes con los diagramas de violín.

```{r boxviolin1, echo=FALSE, fig.align='center'}

ggplot(iris, aes(x = Species, y = Petal.Length)) +
  geom_violin(fill = "blue", color = "white") +
  geom_boxplot(width = 0.1, fill = "white", outlier.color = "red", outlier.size = 4) +
  dark_theme_gray() +
  labs(x = "Especie", y = "Longitud del pétalo") +
  theme(axis.text = element_text(size = 30),
        axis.title = element_text(size = 40),
        plot.title = element_text(size = 50))
```

:::
:::

## Diagrama de dispersión {.smaller}

* Hasta ahora hemos visto distribuciones de una sola v.a., la forma en que podemos describirlas e incluso como las características númericas de las distribuciones se pueden representar gráficamente.

* Pero en la vida real, es muy común que las distribuciones de las v.a. estén relacionadas entre sí. Por ejemplo, la edad y el ingreso mensual de las personas. O el peso y la altura de las personas. O el precio y el tamaño de los departamentos.

* Para visualizar la relación entre dos v.a. se utiliza un ***diagrama de dispersión***. En este diagrama se representa cada observación como un punto en un plano cartesiano, donde el eje $x$ representa una v.a. y el eje $y$ representa otra v.a.

## Ejemplo
::: {.nonincremental}
* Tenemos los datos de la longitud de los pétalos y sépalos de la flor de iris, los cuales se pueden encontrar en el conjunto de datos `iris` de `R`:

```{r table3, tidy=FALSE, echo=FALSE}
knitr::kable(
  head(iris[c(1:5, 50:55, 140:145), c(1, 3, 5)], 17), booktabs = TRUE,
  caption = 'Tabla 3.'
)
```

* Y podemos representar la relación entre la longitud del pétalo y la longitud del sépalo de la flor de iris con un diagrama de dispersión:

```{r scatter1, echo=FALSE, fig.align='center'}
library(ggplot2)
library(ggdark)

ggplot(iris, aes(x = Petal.Length, y = Sepal.Length, color = factor(Species))) +
  geom_point(size = 6) +
  dark_theme_gray() +
  labs(x = "Longitud del pétalo", y = "Longitud del sépalo") +
  theme(axis.text = element_text(size = 30),
        axis.title = element_text(size = 40),
        plot.title = element_text(size = 50)) +
   guides(color = guide_legend(title = "Especie"))
```

:::
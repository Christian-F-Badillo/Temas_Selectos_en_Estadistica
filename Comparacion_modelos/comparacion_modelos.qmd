---
title: "Comparación de Modelos"
subtitle: "Prueba de Hipótesis"
author: "Christian F. Badillo Hernández"
date: 01/21/24
lang: "es"
date-format: "D MMM YYYY"
format:
    revealjs:
        incremental: true
        scrollable: true
        smaller: false   
        theme: night
        logo: img/Lab25_logo_2015.png
        footer: "Temas Selectos en Estadística"
        preview-links: true
        preload-iframes: true
        slide-number: true
        transition: convex
        background-transition: fade
        transition-speed: slow
        navigation-mode: linear
        touch: true
        controls: true
        embed-resources: true
        page-layout: custom
        reference-location: document
        link-external-newwindow: true
        fig-height: 7
        fig-responsive: true
---

## Introducción {.smaller}

- Hasta ahora hemos visto como estimar parámetros y como hacer inferencia sobre ellos. Pero, en la realidad nunca tenemos un solo modelo, siempre tenemos varios modelos que se ajustan a nuestros datos.

- Otra manera de verlo es que siempre tenemos varias hipótesis que queremos probar. 

- En esta clase veremos como comparar modelos y como probar hipótesis sobre ellos.

## Comparación de Modelos {.smaller}

- En estadística, la comparación de modelos es el proceso de seleccionar un modelo estadístico de un conjunto de modelos alternativos, dado un conjunto de datos.

- Incluso cuando realizamos una regresión lineal simple, estamos comparando dos modelos: ***el modelo con la variable independiente y el modelo sin la variable independiente.***

- En otras palabras, tenemos dos hipótesis que queremos probar:

    - $H_0$: $\beta_1 = 0$
    - $H_1$: $\beta_1 \neq 0$

- Una **hipótesis** se define como una afirmación sobre el valor de un parámetro poblacional. En este caso, el parámetro poblacional es $\beta_1$. En general, hablamos de dos tipos de hipótesis:

    - ***Hipótesis nula:*** $H_0$
    - ***Hipótesis alternativa:*** $H_1$

## Prueba de Hipótesis {.smaller}

- Una ***prueba de hipótesis*** es una regla de decisión que nos permite decidir si rechazamos o no la hipótesis nula. Existen diversos tipos de pruebas de hipótesis según el tipo de variable que estemos analizando y el parámetro que estemos estimando.

- Para rechazar o aceptar la hipótesis nula, se utiliza un **estadístico de prueba**. Este estadístico de prueba se calcula a partir de los datos y se compara con una ***región crítica***. Si el estadístico de prueba cae en la región crítica, entonces rechazamos la hipótesis nula.

- La ***región crítica*** se define como el conjunto de valores que toma el estadístico de prueba que nos llevan a rechazar la hipótesis nula. 

- Por ejemplo, si tenemos datos que provienen de una distribución normal, entonces podemos utilizar un test de hipótesis para probar si la media de la distribución es igual a un valor específico. Lo cual se puede expresar como:

    - $H_0$: $\mu = \mu_0$
    - $H_1$: $\mu \neq \mu_0$

    - Es lógico pensar que si $\overline{x}$ es muy diferente de $\mu_0$, entonces rechazamos la hipótesis nula. Pero, ¿qué tan diferente es muy diferente? ¿Cuál es el valor de $\overline{x}$ que nos hace rechazar la hipótesis nula?

## Tipos Error y Poder de la Prueba {.smaller}

- Cuando realizamos una prueba de hipótesis, podemos cometer dos tipos de errores:

    - ***Error tipo I:*** Rechazar la hipótesis nula cuando es verdadera.
    - ***Error tipo II:*** No rechazar la hipótesis nula cuando es falsa.

- Se puede resumir en la siguiente tabla:
$$
\begin{array}{|c|c|c|}
\hline
& \text{No rechazar } H_0 & \text{Rechazar } H_0 \\
\hline
\text{Verdadera} & \text{Decisión correcta} & \text{Error tipo I} \\
\hline
\text{Falsa} & \text{Error tipo II} & \text{Decisión correcta} \\
\hline
\end{array}
$$

- Cada error tiene una probabilidad asociada, denotada por $\alpha$ y $\beta$ respectivamente. Es decir, $P(\text{Error tipo I}) = \alpha$ y $P(\text{Error tipo II}) = \beta$.

- Estos errores están relacionados con el ***poder de la prueba***, el cual se define como $1 - \beta$. Es decir, el poder de la prueba es la probabilidad de rechazar la hipótesis nula cuando es falsa.

##

![](img/TypesOfError.png){width="100%" height=550px}

## Nivel de Significancia {.smaller}

- Siempre se quiere minimizar la probabilidad de cometer ambos errores. Pero, en la práctica, es imposible minimizar ambos errores al mismo tiempo. Por lo tanto, se debe elegir un nivel de significancia $\alpha$ que nos permita minimizar el error que consideremos más importante.

- El error tipo I es el más comúnmente utilizado. Por lo tanto, se suele elegir un nivel de significancia de $\alpha = 0.05$.

- El nivel de significancia se define como la probabilidad de cometer un error tipo I. Es decir, $\alpha = P(\text{Error tipo I})$. El cual se puede expresar como:

    - $\alpha = P(\text{Rechazar } H_0 \mid H_0 \text{ es verdadera})$

- En otras palabras, el nivel de significancia es la probabilidad de rechazar la hipótesis nula cuando es verdadera. Su importancia radica en que nos permite definir la región crítica.

## Pruebas de Hipótesis de una o dos colas {.smaller}

- Las pruebas de hipótesis se pueden clasificar en dos tipos:

    - ***Pruebas de hipótesis de una cola:*** Se rechaza la hipótesis nula si el estadístico de prueba cae en una de las colas de la distribución.
    - ***Pruebas de hipótesis de dos colas:*** Se rechaza la hipótesis nula si el estadístico de prueba cae en alguna de las colas de la distribución.

- Cuando tenemos dos hipótesis alternativas, se suele utilizar una prueba de hipótesis de dos colas. Por ejemplo, si queremos probar que la media de una distribución es diferente de un valor específico, entonces las hipótesis serían:

    - $H_0$: $\mu = \mu_0$
    - $H_1$: $\mu \neq \mu_0$

- Pero no se indica si la media es mayor o menor que $\mu_0$, lo cual define a una prueba de hipótesis de dos colas. Y el nivel de significancia se divide entre las dos colas.

- Cada estadístico de prueba tiene una distribución asociada, que depende del tipo de variable que estemos analizando y el parámetro que estemos estimando.

- Cuando especificamos en nuestra hipótesis alternativa si el parámetro es mayor o menor que un valor específico, entonces se utiliza una prueba de hipótesis de una cola. Si el valor del estadístico de prueba cae en la cola especificada, entonces rechazamos la hipótesis nula. Si decimos que es mayor, la región crítica cae en la cola derecha. Si decimos que es menor, la región crítica cae en la cola izquierda.

## Valor $p$ {.smaller}

- El valor $p$ es la probabilidad de obtener un estadístico de prueba igual o más extremo que el que se obtuvo, asumiendo que la hipótesis nula es verdadera.

- Es decir, si el valor $p$ es muy pequeño, entonces es muy poco probable que la hipótesis nula sea verdadera. Por lo tanto, rechazamos la hipótesis nula.

- Es un debate muy común en estadística, si se debe utilizar el valor $p$ para tomar decisiones. En general, se recomienda utilizar el valor $p$ como una medida de la evidencia en contra de la hipótesis nula. 

- Esta interpretación proviene de la definición de valor $p$. Pero, en la práctica, se suele utilizar el valor $p$ para tomar decisiones (lo cual no es correcto).

- Muchas veces se confunde el valor $p$ con la probabilidad de que la hipótesis nula sea verdadera.

- Igual se toma como un valor de significancia, es decir, si el valor $p$ es menor que el nivel de significancia, entonces se rechaza la hipótesis nula. Pero, esto tampoco es correcto.

- Lo más importante en prueba de hipótesis es ver que todo se basa en la hipótesis nula pero ***observar evidencia en contra de $H_0$ no es evidencia a favor de $H_1$***.

## Prueba de Hipótesis de Normalidad {.smaller}

::: {.nonincremental}
- En la mayoría de las pruebas de hipótesis se va a suponer que los datos provienen de una distribución normal.

- Una forma de verificar si nuestros datos son normales es gráficar el histograma de los datos y ver si tiene forma de campana. Otra forma es utilizar el test de ***Shapiro-Wilk***.

- Este test de hipótesis se utiliza para probar si una muestra proviene de una distribución normal. Las hipótesis son:

    - $H_0$: Los datos provienen de una distribución normal.
    - $H_1$: Los datos no provienen de una distribución normal.

- Se puede utilizar la función `shapiro.test()` para realizar el test de Shapiro-Wilk. El cual devuelve el estadístico de prueba y el valor $p$.

- Usemos los datos de la flor Iris para probar si la longitud del sépalo de la especie *Iris setosa* proviene de una distribución normal.

```{r}
library(tidyverse)
# Cargamos los datos
data("iris")

# Filtramos los datos de la especie Iris setosa
iris_setosa <- iris %>% 
    filter(Species == "setosa")

# Realizamos el test de Shapiro-Wilk
shapiro.test(iris_setosa$Sepal.Length)
```

- El valor $p$ es muy grande, por lo tanto, no tenemos evidencia para rechazar la hipótesis nula. Por lo tanto, podemos asumir que los datos provienen de una distribución normal.

- Esta prueba es muy robusta a violaciones de normalidad. Por lo tanto, si el valor $p$ es muy pequeño, entonces podemos asumir que los datos no provienen de una distribución normal.

:::

## Prueba de medias de una población {.smaller}

- La prueba de medias de una población se utiliza para probar si la media de una población es igual a un valor específico. Las hipótesis son:

    - $H_0$: $\mu = \mu_0$
    - $H_1$: $\mu \neq \mu_0$

- Para realizar esta prueba, se utiliza el estadístico de prueba $t$ de Student. El cual se define como:
$$
t = \frac{\overline{x} - \mu_0}{s / \sqrt{n}}
$$

- Donde $\overline{x}$ es la media muestral, $s$ es la desviación estándar muestral y $n$ es el tamaño de la muestra.

- En general se utiliza una prueba de hipótesis de dos colas. Por lo tanto, la región crítica se define como:
$$
t < -t_{\alpha/2, n-1} \ \ \text{o} \ \ t > t_{\alpha/2, n-1}
$$ 

- Donde $t_{\alpha/2, n-1}$ es el cuantil de orden $\alpha/2$ de la distribución $t$ de Student con $n-1$ grados de libertad.

- La hipótesis nula se rechaza si el estadístico de prueba cae en la región crítica. Normalmente el valor de la hipótesis nula es cero, así $H_0: \mu = 0$. O si tenemos dos grupos de datos, entonces $H_0: \mu_1 - \mu_2 = 0$. Lo que significa que las medias de los dos grupos son iguales.

## Ejemplo t de Student {.smaller}

::: {.nonincremental}
- Usemos los datos de la flor Iris para probar si la longitud del sépalo de la especie *Iris setosa* es igual a 5.5.

```{r echo= TRUE}

# Realizamos el test de Shapiro-Wilk
shapiro.test(iris_setosa$Sepal.Length)

# Realizamos la prueba de hipótesis
t.test(iris_setosa$Sepal.Length, mu = 5.5)
```

- También podemos probar si la longitud del sépalo es distinta en la especie *Iris setosa* y *Iris versicolor*.

```{r echo= TRUE}

# Filtramos los datos de la especie Iris versicolor
iris_versicolor <- iris %>% 
    filter(Species == "versicolor")

# Realizamos la prueba de hipótesis
t.test(iris_setosa$Sepal.Length, iris_versicolor$Sepal.Length)
```

- De estas dos prubas, se puede concluir que existe evidencia para decir que la media de la longitud del sépalo de la especie *Iris setosa* es distinta a 5.5. Y que la media de la longitud del sépalo de la especie *Iris setosa* es distinta a la media de la longitud del sépalo de la especie *Iris versicolor*.

:::

## Prueba de medias de dos poblaciones {.smaller}

::: {.nonincremental}
- El estadístico t sigue una distribución $t$ de Student. Pero, cuando queremos probar si dos medias son iguales, se utiliza una distribución $t$ de Student con $n_1 + n_2 - 2$ grados de libertad.

- Podemos gráficar la distribución $t$ de Student para cuando pensamos que la longitud del sépalo de la especie *Iris setosa* es igual a 5.5.

```{r echo= TRUE}
# Cargamos la librería
library(ggplot2)
library(ggdark)

# Creamos una secuencia de valores
x <- seq(-10, 10, 0.01)

# Calculamos la densidad de la distribución t de Student
y <- dt(x, df = 49)

# Creamos un data frame
df <- data.frame(x, y)

# t value
t_value <- (mean(iris_setosa$Sepal.Length) - 5.5) / (sd(iris_setosa$Sepal.Length) / sqrt(length(iris_setosa$Sepal.Length)))

# Gráficamos la distribución
ggplot(df, aes(x = x, y = y)) +
    geom_line() +
    geom_vline(xintercept = -qt(0.025, df = 49), linetype = "dashed") +
    geom_vline(xintercept = qt(0.025, df = 49), linetype = "dashed") +
    geom_vline(xintercept = 0, linetype = "dashed") +
    geom_area(data = subset(df, x < qt(0.025, df = 49)), fill = "pink", alpha = 0.5) +
    geom_area(data = subset(df, x > qt(0.975, df = 49)), fill = "yellowgreen", alpha = 0.5) +
    geom_area(data = subset(df, x > qt(0.025, df = 49) & x < qt(0.975, df = 49)), fill = "white", alpha = 0.5) +
    geom_vline(xintercept = t_value, linetype = "dashed", color = "red") +
    labs(x = "t", y = "Densidad") +
    dark_theme_gray() + 
    theme(legend.position = "none")
```

```{r echo= TRUE}
# t value
print(t_value)
```

:::

## Prueba de medias de dos poblaciones {.smaller}

::: {.nonincremental}

- Ahora hagamos la misma prueba para la longitud del sépalo de la especie *Iris setosa* y *Iris versicolor* pero de forma direccional, es decir, si la longitud del sépalo de la especie *Iris setosa* es mayor que la longitud del sépalo de la especie *Iris versicolor*.

```{r echo= TRUE}
# Realizamos la prueba de hipótesis
t.test(iris_setosa$Sepal.Length, iris_versicolor$Sepal.Length, alternative = "greater")
```

- En este caso, la región crítica se define como:
$$
t > t_{\alpha, n_1 + n_2 - 2}
$$

- Donde $t_{\alpha, n_1 + n_2 - 2}$ es el cuantil de orden $\alpha$ de la distribución $t$ de Student con $n_1 + n_2 - 2$ grados de libertad.

- EL valor $p$ es $1$. Por lo tanto, no tenemos evidencia para rechazar la hipótesis nula. Es decir, no podemos decir que la longitud del sépalo de la especie *Iris setosa* es mayor que la longitud del sépalo de la especie *Iris versicolor*.

- Gráfiquemos la distribución $t$ de Student para esta prueba.

```{r echo= TRUE}
# Creamos una secuencia de valores
x <- seq(-10, 10, 0.01)

# Calculamos la densidad de la distribución t de Student
y <- dt(x, df = 98)

# Creamos un data frame
df <- data.frame(x, y)

# t value
t_value <- (mean(iris_setosa$Sepal.Length) - mean(iris_versicolor$Sepal.Length)) / (sqrt((sd(iris_setosa$Sepal.Length)^2 / length(iris_setosa$Sepal.Length)) + (sd(iris_versicolor$Sepal.Length)^2 / length(iris_versicolor$Sepal.Length))))

# Gráficamos la distribución
ggplot(df, aes(x = x, y = y)) +
    geom_line() +
    geom_vline(xintercept = qt(0.95, df = 98), linetype = "dashed") +
    geom_vline(xintercept = 0, linetype = "dashed") +
    geom_area(data = subset(df, x > qt(0.95, df = 98)), fill = "yellowgreen", alpha = 0.5) +
    geom_vline(xintercept = t_value, linetype = "dashed", color = "red") +
    labs(x = "t", y = "Densidad") +
    dark_theme_gray() + 
    theme(legend.position = "none")
```

```{r echo= TRUE}
# t value
print(t_value)
```
:::

## T de Student como una regresión lineal {.smaller}

- La prueba de medias de dos poblaciones se puede expresar como una regresión lineal simple. Para ello, se define una variable indicadora $I$ que toma el valor de $1$ si la observación pertenece a la primera población y $0$ si pertenece a la segunda población.

- Por ejemplo, si queremos probar si la longitud del sépalo de la especie *Iris setosa* es igual a 5.5, entonces la variable indicadora se define como:
$$
I = \begin{cases}
1 & \text{si la observación pertenece a la especie Iris setosa} \\
0 & \text{si la observación no pertenece a la especie Iris setosa}
\end{cases}
$$

- Por lo tanto, la prueba de medias de dos poblaciones se puede expresar como:
$$
y = \beta_0 + \beta_1 I + \epsilon
$$

- Donde $\beta_0$ es la media de la segunda población, $\beta_1$ es la diferencia entre las medias de las dos poblaciones y $\epsilon$ es el error.

## T de Student como una regresión lineal {.smaller}

::: {.nonincremental}
- Si queremos probar si la longitud del sépalo de la especie *Iris setosa* es igual a $0$, entonces la regresión lineal se define como:
$$
H_0: \beta_0 = 0 \ \ \text{vs} \ \ H_1: \beta_0 \neq 0
$$

- Donde $\mu$ es la media de la primera población. Podemos ver en R que la función `t.test()` devuelve el mismo valor $t$ que la función `lm()`.

```{r echo= TRUE}
# Realizamos la prueba de hipótesis
t.test(iris_setosa$Sepal.Length)

# Realizamos la regresión lineal
summary(lm(formula = iris_setosa$Sepal.Length ~ 1))
```

- Visualmente la hipótesis nula es equivalente a que la recta de regresión pase por el origen con pendiente cero y la hipótesis alternativa es equivalente a que la recta de regresión no pase por el origen.
```{r echo= TRUE}
# Cargamos la librería
library(ggplot2)
library(ggdark)

# Gráficamos la distribución
ggplot(iris_setosa, aes(y = Sepal.Length, x = 1)) +
    geom_point() +
    geom_hline(yintercept = mean(iris_setosa$Sepal.Length), linetype = "dashed", color = "yellowgreen", linewidth = 2) +
    geom_hline(yintercept = 0, linetype = "dashed", color = "red", linewidth = 2) +
    scale_y_continuous(limits = c(-1, 6)) +
    labs(y = "Longitud del sépalo", x = "Variable indicadora") +
    dark_theme_gray() + 
    theme(legend.position = "none",
        axis.text = element_text(size = 30),
        axis.title = element_text(size = 40),
        plot.title = element_text(size = 50))
```
:::

## T de Student como una regresión lineal {.smaller}

::: {.nonincremental}

- Para probar si la longitud del sépalo de la especie *Iris setosa* es distinta a la longitud del sépalo de la especie *Iris versicolor*, entonces la regresión lineal se define como:
$$
H_0: \mu_1 - \mu_2 = 0 \ \ \text{vs} \ \ H_1: \mu_1 - \mu_2 \neq 0
$$

- Donde $\mu_1$ es la media de la primera población, $\mu_2$ es la media de la segunda población y $\beta_1$ es la diferencia entre las medias de las dos poblaciones. Podemos ver en R que la función `t.test()` devuelve el mismo valor $t$ que la función `lm()`.

```{r echo= TRUE}
# Realizamos la prueba de hipótesis
t.test(iris_setosa$Sepal.Length, iris_versicolor$Sepal.Length)

# Realizamos la regresión lineal
dummy_variable <- c(rep(1, length(iris_setosa$Sepal.Length)), rep(0, length(iris_versicolor$Sepal.Length)))

summary(lm(formula = c(iris_setosa$Sepal.Length, iris_versicolor$Sepal.Length) ~ dummy_variable))
```

- Vemos que el valor de la $t$ de Student para la pendiente es el mismo que el valor $t$ de Student de la prueba de hipótesis. Visualmente esto es:

![](img/t_as_linear_regression.png){width="100%" height=550px}

- Esto se puede comprobar al ver que el valor del intercepto es la media de la segunda población y el valor de la pendiente es la diferencia entre las medias de las dos poblaciones.
```{r echo= TRUE}
print(mean(iris_versicolor$Sepal.Length))
print(mean(iris_setosa$Sepal.Length) - mean(iris_versicolor$Sepal.Length))
```

:::

## T de Student variantes y supuestos {.smaller}

- Los supuestos de la prueba de medias de dos poblaciones son:
    - ***Normalidad:*** Los errores siguen una distribución normal.
    - ***Homocedasticidad:*** La varianza de las dos poblaciones es aproximadamente la misma.
    - ***Independencia:*** Los errores son independientes entre sí. 

- Cuando no se cumple el supuesto de homocedasticidad se puede utilizar la prueba de Welch. La cual se define como:
$$
t = \frac{\overline{x}_1 - \overline{x}_2}{\sqrt{\frac{s_1^2}{n_1} + \frac{s_2^2}{n_2}}}
$$

- Y los grados de libertad se calculan como:
$$
\nu = \frac{\left(\frac{s_1^2}{n_1} + \frac{s_2^2}{n_2}\right)^2}{\frac{\left(\frac{s_1^2}{n_1}\right)^2}{n_1 - 1} + \frac{\left(\frac{s_2^2}{n_2}\right)^2}{n_2 - 1}}
$$

- En R, se puede utilizar la función `t.test()` con el argumento `var.equal = FALSE` para realizar la prueba de Welch.

- Cuando nuestro datos son pareados, es decir, tenemos dos mediciones para cada observación (se mide la presión arterial de una persona antes y después de tomar un medicamento.), se puede utilizar la prueba de medias de dos poblaciones pareadas. La cual se define como:
$$
t = \frac{\overline{d}}{s_d / \sqrt{n}}
$$

- Donde $\overline{d}$ es la media de las diferencias, $s_d$ es la desviación estándar de las diferencias y $n$ es el número de observaciones. En R, se puede utilizar la función `t.test()` con el argumento `paired = TRUE` para realizar la prueba de medias de dos poblaciones pareadas.

## Prueba para medias de más de dos poblaciones {.smaller}

- Cuando queremos probar si las medias de más de dos poblaciones son iguales, se utiliza el análisis de varianza (ANOVA). Las hipótesis son:

    - $H_0$: $\mu_1 = \mu_2 = \cdots = \mu_k$
    - $H_1$: Al menos una de las medias es distinta.

- Para realizar esta prueba, se utiliza el estadístico de prueba $F$. El cual se define como:
$$
F = \frac{MS_{\text{entre}}}{MS_{\text{dentro}}}
$$

- Donde $MS_{\text{entre}}$ es la suma de cuadrados entre grupos dividida entre los grados de libertad entre grupos y $MS_{\text{dentro}}$ es la suma de cuadrados dentro de grupos dividida entre los grados de libertad dentro de grupos.

- La ***suma de cuadrados entre grupos*** se define como:
$$
SS_{\text{entre}} = \sum_{i=1}^k n_i (\overline{x}_i - \overline{x})^2
$$

- Donde $n_i$ es el número de observaciones en el grupo $i$, $\overline{x}_i$ es la media del grupo $i$ y $\overline{x}$ es la media de todas las observaciones.

- La ***suma de cuadrados dentro de grupos*** se define como:
$$
SS_{\text{dentro}} = \sum_{i=1}^k \sum_{j=1}^{n_i} (x_{ij} - \overline{x}_i)^2
$$

- Donde $x_{ij}$ es la observación $j$ del grupo $i$.

- Los ***grados de libertad entre grupos*** se definen como:
$$
\text{Grados de libertad entre grupos} = k - 1
$$

- Donde $k$ es el número de grupos.

- Los ***grados de libertad dentro de grupos*** se definen como:
$$
\text{Grados de libertad dentro de grupos} = n - k
$$

- Donde $n$ es el número total de observaciones.

## ANOVA: Ejemplo {.smaller}

::: {.nonincremental}
- Usemos el dataset de la flor iris para probar si la longitud del sépalo es igual en las tres especies. Las hipótesis son:

    - $H_0$: $\mu_{\text{setosa}} = \mu_{\text{versicolor}} = \mu_{\text{virginica}}$
    - $H_1$: Al menos una de las medias es distinta.

- Realicemos paso por paso la prueba de hipótesis.

```{r echo= TRUE}
library(tidyverse)
# Cargamos los datos
data("iris")

# Realizamos el ANOVA
mean_iris <- iris %>% 
    group_by(Species) %>% 
    summarise(mean = mean(Sepal.Length))

# ANOVA
big_mean <- mean(iris$Sepal.Length)

ss_entre <- ((mean_iris - big_mean)^2) * table(iris$Species)
ss_entre <- sum(ss_entre$mean)

ss_dentro_vector <- c()
for(i in 1:length(unique(iris$Species))){
    ss_dentro_vector[i] <- sum((iris %>% filter(Species == unique(iris$Species)[i]) %>% pull(Sepal.Length) - mean_iris$mean[i])^2)
}

ss_dentro <- sum(ss_dentro_vector)

grades_entre <- length(unique(iris$Species)) - 1
grades_dentro <- length(iris$Sepal.Length) - length(unique(iris$Species))

f_value <- (ss_entre / grades_entre) / (ss_dentro / grades_dentro)


# imprime el valor de F
print(f_value)

# Calculamos el valor p
p_value <- 1 - pf(f_value, grades_entre, grades_dentro)

# imprime el valor de p
print(p_value)

# imprime los grados de libertad
print(grades_entre)
print(grades_dentro)

## imprime suma de cuadrados entre grupos
print(ss_entre)

## imprime suma de cuadrados dentro de grupos
print(ss_dentro)
```

- Podemos comprobar usando la función `aov()` que el valor de $F$ es el mismo.

```{r echo= TRUE}
# Realizamos el ANOVA
summary(aov(Sepal.Length ~ Species, data = iris))
```

- Como antes visualizemos la distribución $F$ de Fisher.

```{r echo= TRUE}
# Cargamos la librería
library(ggplot2)
library(ggdark)

# Creamos una secuencia de valores
x <- seq(0, 120, 0.01)

# Calculamos la densidad de la distribución F de Fisher
y <- df(x, df1 = 2, df2 = 147)

# Creamos un data frame
df <- data.frame(x, y)

# graficamos

ggplot(df, aes(x = x, y = y)) +
    geom_line() +
    geom_vline(xintercept = qf(0.95, df1 = 2, df2 = 147), linetype = "dashed") +
    geom_vline(xintercept = f_value, linetype = "dashed", color = "red") +
    geom_area(data = subset(df, x > qf(0.95, df1 = 2, df2 = 147)), fill = "yellowgreen", alpha = 0.5) +
    labs(x = "F", y = "Densidad") +
    dark_theme_gray() + 
    theme(legend.position = "none",
    axis.text = element_text(size = 30),
        axis.title = element_text(size = 40),
        plot.title = element_text(size = 50))
```
::: 

## ANOVA: Ejemplo {.smaller}

::: {.nonincremental}

- Ahora usemos los datos del dataset `PlantGrowth` de R que nos indica la cosecha de plantas bajo tres tratamientos diferentes. Las hipótesis son:

    - $H_0$: $\mu_{\text{tratamiento 1}} = \mu_{\text{tratamiento 2}} = \mu_{\text{tratamiento 3}}$
    - $H_1$: Al menos una de las medias es distinta.

- Visualicemos los datos usando un boxplot y un digrama de violín.

```{r echo= TRUE}
# Cargamos los datos
data("PlantGrowth")

# Gráficamos los datos

ggplot(PlantGrowth, aes(x = group, y = weight)) +
    geom_violin(fill = "blue", color = "white") +
    geom_boxplot(width = 0.3, fill = "white", outlier.color = "red", outlier.size = 4) +
    stat_summary(fun.y=mean, geom="point", shape=20, size=14, color="pink", fill="pink") +
    labs(x = "Tratamiento", y = "Peso") +
    dark_theme_gray() + 
    theme(legend.position = "none",
    axis.text = element_text(size = 30),
        axis.title = element_text(size = 40),
        plot.title = element_text(size = 50))
```

- Realicemos paso por paso la prueba de hipótesis.
    
```{r echo= TRUE}
# Cargamos los datos
data("PlantGrowth")

# Realizamos el ANOVA
model <- aov(weight ~ group, data = PlantGrowth)

# Imprimimos el resultado
summary(model)
```

- Si asumimos un nivel de significa de $\alpha = 0.05$, entonces rechazamos la hipótesis nula. Es decir, existe evidencia para decir que al menos una de las medias es distinta.

- EL ANOVA nos indica si existe evidencia para decir que al menos una de las medias es distinta. Pero, no nos indica cuáles medias son distintas. Para identificar el grupo, se suele utilizar la prueba post hoc de Tukey, pero en este caso tenemos un grupo control. Por lo tanto, se debe utilizar la prueba post hoc de Dunnett.

- La ***prueba post hoc de Dunnett*** se utiliza para probar si las medias de los grupos de tratamiento son iguales a la media del grupo control. Las hipótesis son:

    - $H_0$: $\mu_{\text{tratamiento}} = \mu_{\text{control}}$
    - $H_1$: $\mu_{\text{tratamiento}} \neq \mu_{\text{control}}$

- Implementemos la prueba en R
```{r echo= TRUE}
#install.packages("DescTools")
library(DescTools)
# Cargamos los datos
data("PlantGrowth")

# Realizamos la prueba post hoc de Dunnett
DunnettTest(weight ~ group, data = PlantGrowth)
```

- El valor p nos indica que no hay evidencia para decir que las medias de los grupos de tratamiento son distintas a la media del grupo control. Pero el ANOVA indico que al menos una de las medias es distinta. 

- Realicemos la prueba de Tukey para ver cuáles medias son distintas.
```{r echo= TRUE}
# Cargamos los datos
data("PlantGrowth")

# Realizamos la prueba post hoc de Tukey
TukeyHSD(aov(weight ~ group, data = PlantGrowth))
```

- Lo que se observa es que la diferencia encontrada en el ANOVA se debe a que la media de los tratamientos 1 y 2 son distintas entre sí, más no a la media del grupo control.

- El uso de pruebas post hoc se debe realizar con cuidado, ya que se aumenta la probabilidad de cometer un error tipo I. Por lo tanto, se debe utilizar un nivel de significancia más pequeño o correcciones de Bonferroni, para controlar el error tipo I.
:::

## ANOVA como una regresión lineal {.smaller}

::: {.nonincremental}
- El ANOVA se puede expresar como una regresión lineal múltiple. Para ello, se define una variable indicadora $I_1, I_2, \ldots, I_k$ que toma el valor de $1$ si la observación pertenece al grupo $i$ y $0$ si pertenece a otro grupo.

- En el caso de nuestro dataset `PlantGrowth`, la variable indicadora se define como:
$$
I_1 = \begin{cases}
1 & \text{si la observación pertenece al grupo i} \\
0 & \text{si la observación no pertenece al grupo i}
\end{cases}
$$ 

- El modelo de regresión lineal múltiple se define como:
$$
y = \beta_0 + \beta_1 I_1 + \beta_2 I_2 + \cdots + \beta_k I_k + \epsilon
$$

- Si la observación pertenece al grupo control entonces $I_1 = I_2 = \cdots = I_k = 0$. Por lo tanto, el modelo se reduce a:
$$
y = \beta_0 + \epsilon
$$

- Si la observación pertenece al primer tratamiento entonces $I_1 = 1$ y $I_2 = \cdots = I_k = 0$. Por lo tanto, el modelo se reduce a:
$$
y = \beta_0 + \beta_1 + \epsilon
$$

- Visto de esta forma, cada $\beta_i$ es la media del grupo $i$ menos la media del grupo control. Por lo tanto, la prueba de hipótesis se puede expresar como:
$$
\begin{align*}
&H_0: \beta_1 = \beta_2 = \cdots = \beta_k = 0 \\ 
&\text{vs} \\
&H_1: \text{Al menos uno de los } \beta_i \text{ es distinto de cero}
\end{align*}
$$

- Visualmente esto es:

![](img/ANOVA_as_lm.png){width="100%" height=550px}

- Recordemos lo que el ANOVA nos dio como resultado.
```{r echo= TRUE}
# Cargamos los datos
data("PlantGrowth")

# Realizamos el ANOVA
model <- aov(weight ~ group, data = PlantGrowth)
summary(model)
```

- Ahora usemos el modelo de regresión lineal múltiple para obtener los valores de $\beta_i$.
```{r echo= TRUE}
# Cargamos los datos
data("PlantGrowth")

# Realizamos el ANOVA
model <- lm(weight ~ group, data = PlantGrowth)
summary(model)
```

- Vemos que nos da los mismos valores de F y las betas son las medias de los grupos menos la media del grupo control. Se ve cuando usamos la prueba post hoc de Dunnett.
```{r echo= TRUE}
#install.packages("DescTools")
library(DescTools)
# Cargamos los datos
data("PlantGrowth")

# Realizamos la prueba post hoc de Dunnett
DunnettTest(weight ~ group, data = PlantGrowth)
```
:::

- Y el intercepto es la media del grupo control.
```{r echo= TRUE}
print(model$coefficients[1])
print(mean(PlantGrowth$weight[PlantGrowth$group == "ctrl"]))
```

## Supuestos del ANOVA y variantes {.smaller}

- Los supuestos del ANOVA son:
    - ***Normalidad:*** Los errores siguen una distribución normal.
    - ***Homocedasticidad:*** La varianza de los grupos es aproximadamente la misma.
    - ***Independencia:*** Los errores son independientes entre sí.
    - ***Independencia:*** Las observaciones de cada grupo son independientes entre sí y dentro de cada grupo.
    - ***Escala de medición:*** Las variables deben ser de escala de intervalo o razón.

- Cuando no se cumple el supuesto de homocedasticidad se puede utilizar el ANOVA de Welch, pero si los datos son desbalanceados, es decir, el número de observaciones en cada grupo es distinto, entonces se debe utilizar el ANOVA clásico.

- Cuando no se cumple el supuesto de normalidad se puede utilizar el ANOVA de Kruskal-Wallis o el ANOVA de Friedman en el caso de datos pareados.

- Cuando se viola el supuesto de independencia se puede utilizar el ANOVA datos pareados, o también conocido como ANOVA de medidas repetidas.

## Prueba Xi-cuadrada {.smaller}

- La prueba Xi-cuadrada se utiliza para probar si la frecuencia de una variable categórica es igual a una distribución específica. Las hipótesis son:

    - $H_0$: No hay asociación entre las variables (son independientes).
    - $H_1$: Existe asociación entre las variables (no son independientes).

- Para realizar esta prueba, se utiliza el estadístico de prueba $\chi^2$. El cual se define como:
$$
\chi^2 = \sum_{i=1}^k \frac{(O_i - E_i)^2}{E_i}
$$

- Donde $O_i$ es la frecuencia observada del grupo $i$ y $E_i$ es la frecuencia esperada del grupo $i$. El estadístico de la prueba sigue una distribución $\chi^2$ con $k-1$ grados de libertad.

- La ***frecuencia esperada*** se define como:
$$
E_i = r_i \times c_i
$$

- Donde $r_i$ es la frecuencia relativa del grupo $i$ y $c_i$ es la frecuencia relativa de la categoría $i$.

- Los ***grados de libertad*** se definen como:
$$
\text{Grados de libertad} = (r - 1) \times (c - 1)
$$

- Donde $r$ es el número de grupos y $c$ es el número de categorías.

## Prueba Xi-cuadrada: Ejemplo {.smaller}

::: {.nonincremental}

- Si tenemos la siguiente tabla de frecuencias observadas:
$$
\begin{array}{|c|c|c|c|c|}
\hline
\text{Categoría} & \text{Grupo 1} & \text{Grupo 2} & \text{Grupo 3} & \text{Grupo 4} \\ \hline
\text{Categoría 1} & 10 & 20 & 30 & 40 \\ \hline
\text{Categoría 2} & 20 & 30 & 40 & 50 \\ \hline
\text{Categoría 3} & 30 & 40 & 50 & 60 \\ \hline
\text{Categoría 4} & 40 & 50 & 60 & 70 \\ \hline
\end{array}
$$

- Entonces, la frecuencia esperada para la celda 1, 1 es:
$$
\begin{align*}
E_{1,1} &= r_1 \times c_1 = \\
&= \frac{100 \times 100}{400} \\
&= 25
\end{align*}
$$

- Realicemos paso por paso la prueba de hipótesis.

```{r echo= TRUE}
# Datos
rows <- rep(c(10, 20, 30, 40), 4)
data <- matrix(rows, ncol = 4, byrow = T)

# Realizamos el test de hipótesis
chisq.test(data)
```

- Podemos ver que el valor de $\chi^2$ es $1$. Por lo tanto, no tenemos evidencia para rechazar la hipótesis nula. Es decir, no podemos decir que existe asociación entre las variables.
:::

## Prueba Xi-cuadrada: Ejemplo {.smaller}

::: {.nonincremental}
- Usemos los datos de `mtcars` para ver si el número de cilindros es independiente del número de marchas. Las hipótesis son:

    - $H_0$: No hay asociación entre las variables (son independientes).
    - $H_1$: Existe asociación entre las variables (no son independientes).

- Realicemos paso por paso la prueba de hipótesis.
```{r echo= TRUE}
# Realizamos el test de hipótesis
chisq.test(table(mtcars$cyl, mtcars$gear), simulate.p.value = TRUE)
```

- Debido a que el valor $p$ es muy pequeño, rechazamos la hipótesis nula. Es decir, existe evidencia para decir que el número de cilindros no es independiente del número de marchas.

- Hay pocos datos, por lo cual es mejor utilizar la prueba exacta de Fisher.
```{r echo= TRUE}
# Realizamos el test de hipótesis
fisher.test(table(mtcars$cyl, mtcars$gear))
```

- El valor $p$ es muy pequeño, por lo tanto, rechazamos la hipótesis nula. Es decir, existe evidencia para decir que el número de cilindros no es independiente del número de marchas.
:::

##

<center>
![](img/bayes_priors_meme.jpg){width="100%" height=550px}
</center>

##

<center>
![](img/meme_1.jpg){width="100%" height=550px}
</center>

##

<center>
![](img/meme_2.jpg){width="100%" height=550px}
</center>

##

<center>
![](img/meme_3.jpg){width="100%" height=550px}
</center>

##

<center>
![](img/meme_4.jpg){width="100%" height=550px}
</center>

##

<center>
![](img/meme_5.jpeg){width="100%" height=550px}
</center>

##

<center>
![](img/meme_6.jpeg){width="100%" height=550px}
</center>

##

<center>
![](img/meme_7.jpeg){width="100%" height=550px}
</center>

##

<center>
![](img/meme_8.jpeg){width="100%" height=550px}
</center>

##

<center>
![](img/meme_9.jpeg){width="100%" height=550px}
</center>

##

<center>
![](img/meme_10.jpg){width="100%" height=550px}
</center>

##

<center>
![](img/meme_11.jpg){width="100%" height=550px}
</center>

##

<center>
![](img/meme_12.jpg){width="100%" height=550px}
</center>

##

<center>
![](img/meme_13.jpg){width="100%" height=550px}
</center>

##

<center>
![](img/meme_14.jpg){width="100%" height=550px}
</center>

##

<center>
![](img/meme_15.jpg){width="100%" height=550px}
</center>

##

<center>
![](img/meme_16.jpg){width="100%" height=550px}
</center>

##

<center>
![](img/meme_17.jpg){width="100%" height=550px}
</center>

##

<center>
![](img/meme_18.jpg){width="100%" height=550px}
</center>

##

<center>
![](img/meme_19.jpg){width="100%" height=550px}
</center>

##

<center>
![](img/meme_20.jpg){width="100%" height=550px}
</center>

##

<center>
![](img/meme_21.jpg){width="100%" height=550px}
</center>

##

<center>
![](img/Statistician_memes_10.png){width="100%" height=550px}
</center>

##

<center>
![](img/meme_22.jpg){width="100%" height=550px}
</center>

##

<center>
![](img/meme_23.jpg){width="100%" height=550px}
</center>

##

<center>
![](img/meme_24.jpg){width="100%" height=550px}
</center>

##

<center>
![](img/meme_25.jpg){width="100%" height=550px}
</center>

##

<center>
![](img/meme_26.jpg){width="100%" height=550px}
</center>

##

<center>
![](img/meme_27.jpg){width="100%" height=550px}
</center>

##

<center>
![](img/meme_28.jpg){width="100%" height=550px}
</center>

##

<center>
![](img/meme_29.jpg){width="100%" height=550px}
</center>

##

<center>
![](img/meme_30.jpg){width="100%" height=550px}
</center>

##

<center>
![](img/meme_31.jpg){width="100%" height=550px}
</center>

##

<center>
![](img/meme_32.jpg){width="100%" height=550px}
</center>

##

<center>
![](img/meme_33.jpg){width="100%" height=550px}
</center>

## Gracias! {.smaller}

<center>
En el rincón cuántico, donde la probabilidad danza,

Se teje un poema, con cifras que la razón alcanza.

En el suave vals de la normalidad, los datos se abrazan,

Mientras la media y la desviación en armonía traspasan.

Cada gráfico es un lienzo, donde la dispersión es arte,

En la paleta de la estadística, la variabilidad parte.

Bajo el cielo estrellado de la regresión, caminamos,

Entre los intervalos de confianza, donde los secretos hallamos.

La simetría de la campana, una elegante poesía,

Mientras la curva se despliega, revelando la sinfonía.

En el telar de la correlación, entrelazamos los hilos,

Cada coeficiente, una melodía que nuestros sentidos cabillos.

Y así, en este éxtasis numérico, la estadística nos guía,

Cantamos con datos, danzamos con la alegría.

Al concluir este verso, agradecemos la estadística que nos une,

En este poema matemático, donde la lógica y la lírica se perfuman.
</center>
> ChatGPT-3

## Código

Todo el código de las presentaciones se encuentra en el siguiente repositorio de GitHub:

<center>
[https://github.com/Christian-F-Badillo/Temas_Selectos_en_Estadistica](https://github.com/Christian-F-Badillo/Temas_Selectos_en_Estadistica)
</center>
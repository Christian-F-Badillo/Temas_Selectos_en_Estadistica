---
title: "Comparación de Modelos"
subtitle: "Prueba de Hipótesis"
author: "Christian F. Badillo Hernández"
date: 01/21/24
lang: "es"
date-format: "D MMM YYYY"
format:
    revealjs:
        incremental: true
        scrollable: true
        smaller: false   
        theme: night
        logo: img/Lab25_logo_2015.png
        footer: "Temas Selectos en Estadística"
        preview-links: true
        preload-iframes: true
        slide-number: true
        transition: convex
        background-transition: fade
        transition-speed: slow
        navigation-mode: linear
        touch: true
        controls: true
        embed-resources: true
        page-layout: custom
        reference-location: document
        link-external-newwindow: true
        fig-height: 7
        fig-responsive: true
---

## Introducción {.smaller}

- Hasta ahora hemos visto como estimar parámetros y como hacer inferencia sobre ellos. Pero, en la realidad nunca tenemos un solo modelo, siempre tenemos varios modelos que se ajustan a nuestros datos.

- Otra manera de verlo es que siempre tenemos varias hipótesis que queremos probar. 

- En esta clase veremos como comparar modelos y como probar hipótesis sobre ellos.

## Comparación de Modelos {.smaller}

- En estadística, la comparación de modelos es el proceso de seleccionar un modelo estadístico de un conjunto de modelos alternativos, dado un conjunto de datos.

- Incluso cuando realizamos una regresión lineal simple, estamos comparando dos modelos: ***el modelo con la variable independiente y el modelo sin la variable independiente.***

- En otras palabras, tenemos dos hipoótesis que queremos probar:

    - $H_0$: $\beta_1 = 0$
    - $H_1$: $\beta_1 \neq 0$

- Una **hipótesis** se define como una afirmación sobre el valor de un parámetro poblacional. En este caso, el parámetro poblacional es $\beta_1$. En general, hablamos de dos tipos de hipótesis:

    - ***Hipótesis nula:*** $H_0$
    - ***Hipótesis alternativa:*** $H_1$

## Prueba de Hipótesis {.smaller}

- Una ***prueba de hipótesis*** es una regla de decisión que nos permite decidir si rechazamos o no la hipótesis nula. Existen diversos tipos de pruebas de hipótesis según el tipo de variable que estemos analizando y el parámetro que estemos estimando.

- Para rechazar o aceptar la hipótesis nula, se utiliza un **estadístico de prueba**. Este estadístico de prueba se calcula a partir de los datos y se compara con una ***región crítica***. Si el estadístico de prueba cae en la región crítica, entonces rechazamos la hipótesis nula.

- La ***región crítica*** se define como el conjunto de valores que toma el estadístico de prueba que nos llevan a rechazar la hipótesis nula. 

- Por ejemplo, si tenemos datos que provienen de una distribución normal, entonces podemos utilizar un test de hipótesis para probar si la media de la distribución es igual a un valor específico. Lo cual se puede expresar como:

    - $H_0$: $\mu = \mu_0$
    - $H_1$: $\mu \neq \mu_0$

    - Es lógico pensar que si $\overline{x}$ es muy diferente de $\mu_0$, entonces rechazamos la hipótesis nula. Pero, ¿qué tan diferente es muy diferente? ¿Cuál es el valor de $\overline{x}$ que nos hace rechazar la hipótesis nula?

## Tipos Error y Poder de la Prueba {.smaller}

- Cuando realizamos una prueba de hipótesis, podemos cometer dos tipos de errores:

    - ***Error tipo I:*** Rechazar la hipótesis nula cuando es verdadera.
    - ***Error tipo II:*** No rechazar la hipótesis nula cuando es falsa.

- Se puede resumir en la siguiente tabla:
$$
\begin{array}{|c|c|c|}
\hline
& \text{No rechazar } H_0 & \text{Rechazar } H_0 \\
\hline
\text{Verdadera} & \text{Decisión correcta} & \text{Error tipo I} \\
\hline
\text{Falsa} & \text{Error tipo II} & \text{Decisión correcta} \\
\hline
\end{array}
$$

- Cada error tiene una probabilidad asociada, denotada por $\alpha$ y $\beta$ respectivamente. Es decir, $P(\text{Error tipo I}) = \alpha$ y $P(\text{Error tipo II}) = \beta$.

- Estos errores están relacionados con el ***poder de la prueba***, el cual se define como $1 - \beta$. Es decir, el poder de la prueba es la probabilidad de rechazar la hipótesis nula cuando es falsa.

##

![](img/TypesOfError.png){width="100%" height=550px}

## Nivel de Significancia {.smaller}

- Siempre se quiere minimizar la probabilidad de cometer ambos errores. Pero, en la práctica, es imposible minimizar ambos errores al mismo tiempo. Por lo tanto, se debe elegir un nivel de significancia $\alpha$ que nos permita minimizar el error que consideremos más importante.

- El error tipo I es el más comúnmente utilizado. Por lo tanto, se suele elegir un nivel de significancia de $\alpha = 0.05$.

- El nivel de significancia se define como la probabilidad de cometer un error tipo I. Es decir, $\alpha = P(\text{Error tipo I})$. El cual se puede expresar como:

    - $\alpha = P(\text{Rechazar } H_0 \mid H_0 \text{ es verdadera})$

- En otras palabras, el nivel de significancia es la probabilidad de rechazar la hipótesis nula cuando es verdadera. Su importancia radica en que nos permite definir la región crítica.

## Pruebas de Hipótesis de una o dos colas {.smaller}

- Las pruebas de hipótesis se pueden clasificar en dos tipos:

    - ***Pruebas de hipótesis de una cola:*** Se rechaza la hipótesis nula si el estadístico de prueba cae en una de las colas de la distribución.
    - ***Pruebas de hipótesis de dos colas:*** Se rechaza la hipótesis nula si el estadístico de prueba cae en alguna de las colas de la distribución.

- Cuando tenemos dos hipótesis alternativas, se suele utilizar una prueba de hipótesis de dos colas. Por ejemplo, si queremos probar que la media de una distribución es diferente de un valor específico, entonces las hipótesis serían:

    - $H_0$: $\mu = \mu_0$
    - $H_1$: $\mu \neq \mu_0$

- Pero no indica si la media es mayor o menor que $\mu_0$. Por lo tanto, se utiliza una prueba de hipótesis de dos colas. Y el nivel de significancia se divide entre las dos colas.

- Cada estadístico de prueba tiene una distribución asociada, que depende del tipo de variable que estemos analizando y el parámetro que estemos estimando.

- Cuando especificamos en nuestra hipótesis alternativa que el parámetro es mayor o menor que un valor específico, entonces se utiliza una prueba de hipótesis de una cola.

## Valor $p$ {.smaller}

- El valor $p$ es la probabilidad de obtener un estadístico de prueba igual o más extremo que el que se obtuvo, asumiendo que la hipótesis nula es verdadera.

- Es decir, si el valor $p$ es muy pequeño, entonces es muy poco probable que la hipótesis nula sea verdadera. Por lo tanto, rechazamos la hipótesis nula.

- Es un debate muy común en estadística, si se debe utilizar el valor $p$ para tomar decisiones. En general, se recomienda utilizar el valor $p$ como una medida de la evidencia en contra de la hipótesis nula. 

- Esta interpretación proviene de la definición de valor $p$. Pero, en la práctica, se suele utilizar el valor $p$ para tomar decisiones (lo cual no es correcto).

- Muchas veces se confunde el valor $p$ con la probabilidad de que la hipótesis nula sea verdadera.

- Igual se toma como un valor de significancia, es decir, si el valor $p$ es menor que el nivel de significancia, entonces se rechaza la hipótesis nula. Pero, esto tampoco es correcto.

- Lo más importante en prueba de hipótesis es ver que todo se basa en la hipótesis nula, ***observar evidencia en contra de $H_0$ no es evidencia a favor de $H_1$***.

## Prueba de Hipótesis de Normalidad {.smaller}

- En la mayoría de las pruebas de hipótesis se va a suponer que los datos provienen de una distribución normal.

- Una forma de verificar si nuestros datos son normales es gráficar el histograma de los datos y ver si tiene forma de campana. Otra forma es utilizar el test de ***Shapiro-Wilk***.

- Este test de hipótesis se utiliza para probar si una muestra proviene de una distribución normal. Las hipótesis son:

    - $H_0$: Los datos provienen de una distribución normal.
    - $H_1$: Los datos no provienen de una distribución normal.

- Se puede utilizar la función `shapiro.test()` para realizar el test de Shapiro-Wilk. El cual devuelve el estadístico de prueba y el valor $p$.

- Usemos los datos de la flor Iris para probar si la longitud del sépalo de la especie *Iris setosa* proviene de una distribución normal.

```{r}
library(tidyverse)
# Cargamos los datos
data("iris")

# Filtramos los datos de la especie Iris setosa
iris_setosa <- iris %>% 
    filter(Species == "setosa")

# Realizamos el test de Shapiro-Wilk
shapiro.test(iris_setosa$Sepal.Length)
```

- El valor $p$ es muy grande, por lo tanto, no tenemos evidencia para rechazar la hipótesis nula. Por lo tanto, podemos asumir que los datos provienen de una distribución normal.

- Esta prueba es muy robusta a violaciones de normalidad. Por lo tanto, si el valor $p$ es muy pequeño, entonces podemos asumir que los datos no provienen de una distribución normal.

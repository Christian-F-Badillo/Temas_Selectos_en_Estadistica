---
title: "Estadística Inferencial"
subtitle: "Estimación de parámetros Bayesiana"
author: "Christian F. Badillo Hernández"
date: 01/15/24
lang: "es"
date-format: "D MMM YYYY"
format:
    revealjs:
        incremental: true
        scrollable: true
        smaller: false   
        theme: night
        logo: img/Lab25_logo_2015.png
        footer: "Temas Selectos en Estadística"
        preview-links: true
        preload-iframes: true
        slide-number: true
        transition: convex
        background-transition: fade
        transition-speed: slow
        navigation-mode: linear
        touch: true
        controls: true
        embed-resources: true
        page-layout: custom
        reference-location: document
        link-external-newwindow: true
        fig-height: 7
        fig-responsive: true
---

## Teorema de Bayes {.smaller}

- Anteriormente vimos el teorema de Bayes para dos eventos $A$ y $B$:
$$
P(A|B)=\frac{P(B|A)P(A)}{P(B)}
$$

- El termino $P(A|B)$ se conoce como la **posterior** de $A$ dado $B$.

- El termino $P(B|A)$ se conoce como la **verosimilitud** de $B$ dado $A$.

- El termino $P(A)$ se conoce como el **prior** de $A$.

- El termino $P(B)$ se conoce como la **verosimilitud marginal** de $B$. 

## Ejemplo 1. {.smaller}

- Supongamos que somos doctes y queremos saber la probabilidad de que alguien tenga Covid-19, dado que salio positivo en la prueba. Sabemos que la prevalencia de Covid-19 en la población es de $0.65$. Y que la prueba tiene una sensibilidad de $0.97$ y una especificidad de $0.8$. ¿Cuál es la probabilidad de que alguien tenga Covid-19, dado que salio positivo en la prueba?

- Sea $A$ el evento de que alguien tenga Covid-19 y $B$ el evento de que alguien salga positivo en la prueba. Entonces, tenemos que:
$$
\begin{align*}
P(A|B)&=\frac{P(B|A)P(A)}{P(B)}= \\
&\frac{P(B|A)P(A)}{P(B|A)P(A)+P(B|A^c)P(A^c)}
\end{align*}
$$

- Donde $P(B|A)=0.97$, $P(A)=0.65$ y $P(B|A^c)=0.2$. Por lo tanto:
$$
P(A|B)=\frac{0.97\times 0.65}{0.97\times 0.65+0.2\times 0.35}=0.9
$$

## Ejempl0 2. {.smaller}

- Si tenemos dos urnas con bolas blancas y negras. En la primera urna hay $4$ bolas blancas y $6$ bolas negras. En la segunda urna hay $2$ bolas blancas y $8$ bolas negras. Si elegimos una urna al azar y sacamos una bola blanca. ¿Cuál es la probabilidad de que la bola haya salido de la primera urna?

- Sea $A$ el evento de que la bola salga de la primera urna y $B$ el evento de que la bola sea blanca. Entonces, tenemos que:
$$
\begin{align*}
P(A|B)&=\frac{P(B|A)P(A)}{P(B)}= \\
&\frac{P(B|A)P(A)}{P(B|A)P(A)+P(B|A^c)P(A^c)}
\end{align*}
$$

- Donde $P(B|A)=0.4$, $P(A)=0.5$ y $P(B|A^c)=0.2$. Por lo tanto:
$$
P(A|B)=\frac{0.4\times 0.5}{0.4\times 0.5+0.2\times 0.5}=0.6
$$

- Si ahora sacamos una bola negra. ¿Cuál es la probabilidad de que la bola haya salido de la primera urna?

- Respuesta:
$$
P(A|B^c)=\frac{0.6\times 0.5}{0.6\times 0.5+0.8\times 0.5}=0.4286
$$

## Ejemplo 3. {.smaller}

- Imagina que tienes dos cajas de galletas, cada una con dos tipos de galletas: chocolate y vainilla. La Caja 1 tiene 30% de galletas de chocolate y 70% de galletas de vainilla, mientras que la Caja 2 tiene 60% de galletas de chocolate y 40% de galletas de vainilla. Ahora, imagina que eliges una caja al azar y sacas una galleta. Si la galleta es de chocolate, ¿cuál es la probabilidad de que haya salido de la Caja 1?

- Respuesta:
$$
P(A|B)=\frac{0.5\times 0.3}{0.5\times 0.3+0.5\times 0.6}=0.3333
$$

## Estimación de parámetros {.smaller}

- En la estadística inferencial, tenemos una muestra de datos $x_1,\ldots,x_n$ que provienen de una distribución de probabilidad $f(x|\theta)$, donde $\theta$ es un parámetro desconocido.

- Ya vimos dos métodos para estimar $\theta$:
    - **Estimación de máxima verosimilitud**. Seleccionamos el valor de $\theta$ que maximiza la verosimilitud de los datos.
    - **Estimación por mínimos cuadrados**. Seleccionamos el valor de $\theta$ que minimiza la suma de los cuadrados de las diferencias entre los datos y el modelo.

- En este tema veremos un tercer método para estimar $\theta$. Este método se conoce como **estimación Bayesiana**.

- Utilizaremos el teorema de Bayes para estimar $\theta$. Existen dos formas de resolver el teorema de Bayes:
    - ***Analíticamente:*** En este caso, es posible calcular la posterior de $\theta$ de forma analítica con métodos de integración.
    - ***Mediante algoritmos:*** Cuando no es posible calcular la posterior de forma analítica, podemos utilizar algoritmos para aproximar la posterior de $\theta$. Los algoritmos más comunes son el **Metropolis-Hastings** y sus variantes, tales como el **muestreo de Gibbs** y el **muestreo Hamiltoniano**. En conjunto estos algoritmos se conocen como **algoritmos MCMC** (Markov Chain Monte Carlo).

# Método analítico

## Método analítico {.smaller}

- Supongamos que tenemos una muestra de datos $x_1,\ldots,x_n$ que provienen de una distribución de probabilidad $f(x|\theta)$, donde $\theta$ es un parámetro desconocido. El teorema de Bayes nos dice que:
$$
P(\theta|x_1,\ldots,x_n)=\frac{P(x_1,\ldots,x_n|\theta)P(\theta)}{P(x_1,\ldots,x_n)}
$$

- Donde $P(\theta|x_1,\ldots,x_n)$ es la posterior de $\theta$, $P(x_1,\ldots,x_n|\theta)$ es la verosimilitud de $\theta$, $P(\theta)$ es el prior de $\theta$ y $P(x_1,\ldots,x_n)$ es la verosimilitud marginal de $\theta$.

- El denominador $P(x_1,\ldots,x_n)$ es una integral que se conoce como **evidencia**. Esta integral es muy difícil de calcular en la mayoria de los casos. 

- Para evitar problemas, en sus incios se usaban [priors **conjugados**](https://en.wikipedia.org/wiki/Conjugate_prior#Table_of_conjugate_distributions). Estos priors tienen la propiedad de que la posterior es de la misma familia que el prior. Permitiendo así, calcular la posterior de forma analítica.

- Sin embargo, en la actualidad, se utilizan algoritmos MCMC para aproximar la posterior de $\theta$.

## Ejemplo {.smaller}

- El ejemplo más sencillo para entender la estimación Bayesiana es el caso de una moneda. Supongamos que tenemos una moneda y queremos estimar la probabilidad de que salga cara. Para esto, lanzamos la moneda 20 veces y obtenemos 15 caras.

- El primer paso es definir la veroimilitud de $\theta$, o en otras palabras, el modelo que describe la probabilidad de obtener una cara. En este caso, el modelo es una distribución binomial con parámetros $n=20$ y $\theta$:
$$
f(x|\theta)= \theta^x(1-\theta)^{20-x}
$$

- El segundo paso es espcificar el prior de $\theta$. En este caso, el prior tiene que tener dos propiedaes:
    - El prior deber de modelar una probabilidad. Por lo tanto, el prior debe de estar entre 0 y 1.
    - Para poder calcular la posterior, la forma del prior debe de ser la misma que la de la verosimilitud.

- ¿Existe alguna distribución que cumpla con estas dos propiedades? 
    - Si, la distribución Beta. La distribución Beta tiene dos parámetros $\alpha$ y $\beta$ y su función de densidad es:
$$
f(\theta|\alpha,\beta)=\frac{\theta^{\alpha-1}(1-\theta)^{\beta-1}}{B(\alpha,\beta)}
$$

- Donde $B(\alpha,\beta)$ es la función Beta. La función Beta es una constante de normalización que hace que la integral de la distribución Beta sea igual a 1.

## Ejemplo {.smaller}

- Sabiendo nuestro prior y nuestra verosimilitud, podemos ponerlos en el teorema de Bayes, la espresión resultante es:
$$
\begin{align*}
P(\theta|x_1,\ldots,x_n)&=\frac{P(x_1,\ldots,x_n|\theta)P(\theta)}{P(x_1,\ldots,x_n)}= \\
&\frac{\theta^{\sum x_i}(1-\theta)^{n-\sum x_i}\frac{\theta^{\alpha-1}(1-\theta)^{\beta-1}}{B(\alpha,\beta)}}{\int_0^1 \theta^{\sum x_i}(1-\theta)^{n-\sum x_i}\frac{\theta^{\alpha-1}(1-\theta)^{\beta-1}}{B(\alpha,\beta)}d\theta}
\end{align*}
$$

- Para resaltar la importancia de usar el prior conjugado, veamos que el numerador de la expresión anterior es igual a:
$$
\begin{align*}
&\theta^{\sum x_i}(1-\theta)^{n-\sum x_i}\frac{\theta^{\alpha-1}(1-\theta)^{\beta-1}}{B(\alpha,\beta)}=\\
&\theta^{\sum x_i+\alpha-1}(1-\theta)^{n-\sum x_i+\beta-1}\frac{1}{B(\alpha,\beta)}
\end{align*}
$$

- En el denominador sucede la misma simplificación. Pero nos queda un factor $\frac{1}{B(\alpha,\beta)}$ tanto en el numerador como en el denominador. Pero dado que $B(\alpha,\beta)$ es una constante, podemos sacarla de la integral. Resultando en:
$$
\begin{align*}
&P(\theta|x_1,\ldots,x_n)= \\
&\frac{\theta^{\sum x_i+\alpha-1}(1-\theta)^{n-\sum x_i+\beta-1} \frac{1}{B(\alpha,\beta)}}{ \frac{1}{B(\alpha,\beta)}\int_0^1 \theta^{\sum x_i+\alpha-1}(1-\theta)^{n-\sum x_i+\beta-1}d\theta}
\end{align*}
$$

- Dado que el numerador y el denominador tienen el mismo factor, podemos simplificarlos. Resultando en:
$$
P(\theta|x_1,\ldots,x_n)=\frac{\theta^{\sum x_i+\alpha-1}(1-\theta)^{n-\sum x_i+\beta-1}}{\int_0^1 \theta^{\sum x_i+\alpha-1}(1-\theta)^{n-\sum x_i+\beta-1}d\theta}
$$

- Comparemos esta expresión con la distribución Beta y recordando que la función Beta es una constante de normalización, tenemos que:
$$
f(\theta|\alpha,\beta)=\frac{\theta^{\alpha-1}(1-\theta)^{\beta-1}}{B(\alpha,\beta)}
$$

- Entonces, podemos ver que la posterior de $\theta$ es una distribución Beta con parámetros $\alpha+\sum x_i$ y $\beta+n-\sum x_i$.

- Por lo tanto, el prior Beta nos ayudo a calcular la posterior de $\theta$ de forma analítica y ***¡¡¡¡ sin realizar ninguna integral !!!!***

## Ejemplo {.smaller}

::: {.nonincremental}
- Veamos la expresion de la posterior de $\theta$:
$$
P(\theta|x_1,\ldots,x_n)=\frac{\theta^{\sum x_i+\alpha-1}(1-\theta)^{n-\sum x_i+\beta-1}}{\int_0^1 \theta^{\sum x_i+\alpha-1}(1-\theta)^{n-\sum x_i+\beta-1}d\theta}
$$

- O de forma equivalente:
$$
P(\theta|x_1,\ldots,x_n)= Beta(\theta|\alpha+\sum x_i,\beta+n-\sum x_i)
$$

- Ya tenemos la expresión de la posterior de $\theta$. Pero no hemos elegido los valores de $\alpha$ y $\beta$. ¿Cómo elegimos los valores de $\alpha$ y $\beta$? 

- La respuesta es que depende de lo que sepamos de $\theta$ antes de ver los datos. Por ejemplo, si no sabemos nada de $\theta$, podemos elegir $\alpha=1$ y $\beta=1$. Esto es equivalente a decir que $\theta$ tiene una distribución uniforme entre 0 y 1.

- Si pensamos que $\theta$ es más probable que sea cercano a 0.5, podemos elegir $\alpha=2$ y $\beta=2$. Esto es equivalente a decir que $\theta$ tiene una distribución centrada en 0.5.

- Visualicemos estos priors:
```{r}
library(ggplot2)
library(ggdark)

alpha <- c(1, 2)
betas <- c(1, 2)
theta <- seq(0, 1, 0.01)

ggplot() +
    geom_line(aes(x = theta, y = dbeta(theta, alpha[1], betas[1]), color = "red")) +
    geom_line(aes(x = theta, y = dbeta(theta, alpha[2], betas[2]), color = "white")) +
    labs(x = expression(theta), y = "Densidad") +
    dark_theme_gray() +
    scale_color_manual("Prior", values = c("red", "white"), labels = c("\u03B1 = 1, \u03B2 = 1", "\u03B1 = 2, \u03B2 = 2")) +
    theme(axis.text = element_text(size = 30),
        axis.title = element_text(size = 40),
        plot.title = element_text(size = 50),
        legend.title = element_text(size=25),
        legend.text = element_text(size=20),
        legend.position = c(.07, .8),
        legend.key.size = unit(2, 'cm'), #change legend key size
        legend.key.height = unit(2, 'cm'), #change legend key height
        legend.key.width = unit(2, 'cm'))
```

- Utilizando estos priors, podemos calcular la posterior de $\theta$:
```{r}
caras <- 15
n <- 20

ggplot() +
    geom_line(aes(x = theta, y = dbeta(theta, alpha[1] + caras, betas[1] + n - caras), color = "red")) +
    geom_line(aes(x = theta, y = dbeta(theta, alpha[2] + caras, betas[2] + n - caras), color = "white")) +
    labs(x = expression(theta), y = "Densidad") +
    dark_theme_gray() +
    scale_color_manual("Prior", values = c("red", "white"), labels = c("\u03B1 = 1, \u03B2 = 1", "\u03B1 = 2, \u03B2 = 2")) +
    theme(axis.text = element_text(size = 30),
        axis.title = element_text(size = 40),
        plot.title = element_text(size = 50),
        legend.title = element_text(size=25),
        legend.text = element_text(size=20),
        legend.position = c(.11, .8),
        legend.key.size = unit(2, 'cm'), #change legend key size
        legend.key.height = unit(2, 'cm'), #change legend key height
        legend.key.width = unit(2, 'cm'))
```
:::

## Ejemplo {.smaller}

- Ya tenemos la posterior de $\theta$. Pero, ¿cómo podemos utilizarla para estimar $\theta$?

- Una forma de estimar $\theta$ es utilizando la **media posterior** o la **moda posterior** (*maximum a posteriori*). Usemos la media posterior, la cual se define como:
$$
\begin{align*}
&E[\theta|x_1,\ldots,x_n]=\int_0^1 \theta P(\theta|x_1,\ldots,x_n)d\theta= \\
&\int_0^1 \theta Beta(\theta|\alpha+\sum x_i,\beta+n-\sum x_i)d\theta= \\
&\frac{\alpha+\sum x_i}{\alpha+\sum x_i+\beta+n-\sum x_i}= \\
&\frac{\alpha+\sum x_i}{\alpha+\beta+n}
\end{align*}
$$

- Entonces para $\alpha=1$, $\beta=1$, $\sum x_i=15$ y $n=20$, tenemos que:
$$
E[\theta|x_1,\ldots,x_n]=\frac{1+15}{1+1+20}=0.72
$$

- Y para $\alpha=2$, $\beta=2$, $\sum x_i=15$ y $n=20$, tenemos que:
$$
E[\theta|x_1,\ldots,x_n]=\frac{2+15}{2+2+20}=0.7083
$$

```{r}
caras <- 15
n <- 20

ggplot() +
    geom_line(aes(x = theta, y = dbeta(theta, alpha[1] + caras, betas[1] + n - caras), color = "red")) +
    geom_line(aes(x = theta, y = dbeta(theta, alpha[2] + caras, betas[2] + n - caras), color = "white")) +
    geom_vline(xintercept = (alpha[1] + caras)/(alpha[1] + betas[1] + n), color = "red", linetype = "dashed") +
    geom_vline(xintercept = (alpha[2] + caras)/(alpha[2] + betas[2] + n), color = "white", linetype = "dashed") +
    labs(x = expression(theta), y = "Densidad") +
    dark_theme_gray() +
    scale_color_manual("Prior", values = c("red", "white"), labels = c("\u03B1 = 1, \u03B2 = 1", "\u03B1 = 2, \u03B2 = 2")) +
    theme(axis.text = element_text(size = 30),
        axis.title = element_text(size = 40),
        plot.title = element_text(size = 50),
        legend.title = element_text(size=25),
        legend.text = element_text(size=20),
        legend.position = c(.11, .8),
        legend.key.size = unit(2, 'cm'), #change legend key size
        legend.key.height = unit(2, 'cm'), #change legend key height
        legend.key.width = unit(2, 'cm'))
```

## Intervalos de credibilidad {.smaller}

::: {.nonincremental}
- Otra forma de estimar $\theta$ es utilizando un **intervalo de credibilidad**. Un intervalo de credibilidad es un intervalo que contiene un cierto porcentaje de la posterior de $\theta$. Por ejemplo, si queremos un intervalo de credibilidad del 95%, entonces queremos un intervalo que contenga el 95% de la posterior de $\theta$.

- Son la contraparte Bayesiana de los intervalos de confianza. Para calcular un intervalo de credibilidad, tenemos que calcular los cuantiles de la posterior de $\theta$. Por ejemplo, si queremos un intervalo de credibilidad del 95%, tenemos que calcular el cuantil 0.025 y el cuantil 0.975 de la posterior de $\theta$.

- En el ejemplo de la moneda, tenemos que:
```{r echo=TRUE}
q_prior1 <- qbeta(c(0.025, 0.975), alpha[1] + caras, betas[1] + n - caras)
q_prior2 <- qbeta(c(0.025, 0.975), alpha[2] + caras, betas[2] + n - caras)

print(paste("Intervalo de credibilidad del 95% para el prior 1: [", round(q_prior1[1], 4), ",", round(q_prior1[2], 4), "]"))

print(paste("Intervalo de credibilidad del 95% para el prior 2: [", round(q_prior2[1], 4), ",", round(q_prior2[2], 4), "]"))
```

- Podemos visualizar estos intervalos:
```{r}

ggplot() +
    geom_line(aes(x = theta, y = dbeta(theta, alpha[1] + caras, betas[1] + n - caras), color = "red")) +
    geom_line(aes(x = theta, y = dbeta(theta, alpha[2] + caras, betas[2] + n - caras), color = "white")) +
    geom_vline(xintercept = q_prior1[1], color = "red", linetype = "dashed") +
    geom_vline(xintercept = q_prior1[2], color = "red", linetype = "dashed") +
    geom_vline(xintercept = q_prior2[1], color = "white", linetype = "dashed") +
    geom_vline(xintercept = q_prior2[2], color = "white", linetype = "dashed") +
    labs(x = expression(theta), y = "Densidad") +
    dark_theme_gray() +
    scale_color_manual("Prior", values = c("red", "white"), labels = c("\u03B1 = 1, \u03B2 = 1", "\u03B1 = 2, \u03B2 = 2")) +
    theme(axis.text = element_text(size = 30),
        axis.title = element_text(size = 40),
        plot.title = element_text(size = 50),
        legend.title = element_text(size=25),
        legend.text = element_text(size=20),
        legend.position = c(.11, .8),
        legend.key.size = unit(2, 'cm'), #change legend key size
        legend.key.height = unit(2, 'cm'), #change legend key height
        legend.key.width = unit(2, 'cm'))
```

:::

# Cadenas de Markov Monte Carlo (MCMC)

## Cadenas de Markov Monte Carlo (MCMC) {.smaller}

- En el ejemplo anterior, vimos que el prior conjugado nos ayudo a calcular la posterior de $\theta$ de forma analítica. Pero, ¿qué pasa si no tenemos un prior conjugado?

- En este caso, podemos utilizar algoritmos MCMC para aproximar la posterior de $\theta$.

- Los algoritmos MCMC son algoritmos que generan una secuencia de muestras de una distribución de probabilidad. Estas muestras se conocen como **cadenas de Markov**.

- La idea de estos algoritmos es generar una secuencia de muestras de una distribución de probabilidad $f(x)$, donde $x$ es un vector de variables aleatorias. Estas muestras se generan de tal forma que la distribución de probabilidad de la muestra $x_t$ depende únicamente de la muestra anterior $x_{t-1}$. Es decir, la distribución de probabilidad de la muestra $x_t$ es una **distribución condicional** de la muestra anterior $x_{t-1}$:
$$
f(x_t|x_{t-1})
$$

- Esta propiedad se conoce como **propiedad de Markov**. Y una secuencia de muestras que cumple con esta propiedad se conoce como **cadena de Markov**.

- La idea de los algoritmos MCMC es generar una cadena de Markov cuya distribución de probabilidad estacionaria sea la distribución de probabilidad $f(x)$. Estacionaria significa que la distribución de probabilidad de la muestra $x_t$ es la misma que la distribución posterior $f(x)$:
$$
f(x_t)=f(x)
$$

- Si logramos generar una cadena de Markov cuya distribución de probabilidad estacionaria sea la distribución de probabilidad $f(x)$, entonces podemos utilizar las muestras de la cadena para aproximar la distribución de probabilidad $f(x)$.

## Cadenas de Markov Monte Carlo (MCMC) {.smaller}

- Existen varios algoritmos MCMC. Los más comunes son:
    - **Metropolis-Hastings**. Este algoritmo es el más sencillo de implementar. Sin embargo, es el más lento de los tres.
    - **Muestreo de Gibbs**. El muestreo de Gibbs es más rápido que el Metropolis-Hastings. Sin embargo, no siempre es posible utilizarlo, ya que requiere que la distribución de probabilidad $f(x)$ se pueda descomponer en distribuciones condicionales.
    - **Muestreo Hamiltoniano**. El muestreo Hamiltoniano es el más rápido de los dos anteriores. Sin embargo, es el más difícil de implementar y solo se puede utilizar en distribuciones de probabilidad continuas.
    - **Muestreo NUTS**. El muestreo NUTS es una variante del muestreo Hamiltoniano. Este algoritmo es el más rápido.

- Existe software que implementa estos algoritmos. El más popular es [Stan](https://mc-stan.org/). Stan es un lenguaje de programación que permite especificar modelos estadísticos y que utiliza el muestreo NUTS para aproximar la posterior de los parámetros.

- Otro software popular es [PyMC3](https://docs.pymc.io/). PyMC3 es una librería de Python que permite especificar modelos estadísticos y que utiliza el muestreo NUTS para aproximar la posterior de los parámetros.

- Un tercer software es [JAGS](https://mcmc-jags.sourceforge.io/). JAGS es un lenguaje de programación que permite especificar modelos estadísticos y que utiliza el muestreo de Gibbs para aproximar la posterior de los parámetros.

## Caminata aleatoria Metropolis-Hastings (MH) {.smaller}
::: {.nonincremental}
- Las cadenas de Markov se pueden generar utilizando un algoritmo de caminata aleatoria. Este algoritmo se conoce como **caminata aleatoria Metropolis-Hastings** (MH).

- Un ejemplo muy sencillo de una caminata aleatoria es el siguiente:
    - Supongamos que estamos en el punto $x_t$.
    - Para generar el siguiente punto $x_{t+1}$, generamos un número aleatorio $u$ entre 0 y 1.
    - Si $u<0.5$, entonces $x_{t+1}=x_t-1$.
    - Si $u\geq 0.5$, entonces $x_{t+1}=x_t+1$.

 - Implementemos este algoritmo en R:

```{r echo=TRUE}
# Definimos el número de muestras
n <- 1000
# Definimos el vector de muestras
x <- rep(0, n)
# Definimos el punto inicial
x[1] <- 0
# Generamos las muestras
set.seed(123)
for (i in 2:n) {
    u <- runif(1)
    if (u < 0.5) {
        x[i] <- x[i-1] - 1
    } else {
        x[i] <- x[i-1] + 1
    }
}
# Graficamos las muestras
ggplot() +
    geom_line(aes(x = 1:n, y = x), color = "white") +
    labs(x = "Muestra", y = "x") +
    dark_theme_gray() +
    theme(axis.text = element_text(size = 30),
        axis.title = element_text(size = 40),
        plot.title = element_text(size = 50))
```

- Podemos visualizar las muestras en un histograma:
```{r echo=TRUE}
ggplot() +
    geom_histogram(aes(x = x, y = ..density..), bins = 20, color = "white", fill = "white") +
    labs(x = "x", y = "Densidad") +
    dark_theme_gray() +
    theme(axis.text = element_text(size = 30),
        axis.title = element_text(size = 40),
        plot.title = element_text(size = 50))
```

:::

## Caminata aleatoria Metropolis-Hastings (MH) {.smaller}

::: {.nonincremental}

- En el ejemplo anterior, la probabilidad de que el siguiente punto sea $x_{t+1}=x_t-1$ es $0.5$. Y la probabilidad de que el siguiente punto sea $x_{t+1}=x_t+1$ es $0.5$.

- Veamos un ejemplo un poco más complicado.

- Supongamos que somos Claudia Sheinbaum y queremos ir a los distintos estados de México para obtener votos y tener que llevar la menor cantidad de acarreados. Una forma de decidir cuantas veces visitaremos cada estado es utilizando la cantidad de habitantes. Por el moemnto pensemos en 7 estados: CDMX, EdoMex, Jalisco, Nuevo León, Puebla, Veracruz y Yucatán. Y supongamos que la cantidad de habitantes de cada estado es:
```{r echo=FALSE}
habitantes <- c(9, 16, 8, 5, 6, 8, 2)
estado <- c("CDMX", "EdoMex", "Jalisco", "Nuevo León", "Puebla", "Veracruz", "Yucatán")

knitr::kable(data.frame(estado, habitantes))
```

- La decisión de cuantas veces visitaremos cada estado la podemos modelar como en la caminata aleatoria anterior. Es decir, si estamos en el estado $x_t$, la probabilidad de que el siguiente estado sea $x_{t+1}$ es 1 si los habitantes del estado $x_{t+1}$ son más que los habitantes del estado $x_t$

- Si los habitantes del estado $x_{t+1}$ son menos que los habitantes del estado $x_t$, entonces se usa un número aleatorio $u$ entre 0 y 1. 
    - Si $u<\frac{habitantes(x_{t+1})}{habitantes(x_t)}$, entonces $x_{t+1}= x_{t} + 1$. 
    - Si $u\geq \frac{habitantes(x_{t+1})}{habitantes(x_t)}$, entonces $x_{t+1}=x_t$.

- Cada estado sería un valor del 1 al 7. Por lo tanto, podemos utilizar el algoritmo de la caminata aleatoria anterior para generar la secuencia de estados que visitaremos. La probabilidad de ir a 0 seria 0 y la probabilidad de ir a 8 seria 0. No podemos ir a un estado que no existe.

- Implementemos este algoritmo en R:

```{r echo=TRUE}
# Definimos el número de muestras
n <- 1000
# Definimos el vector de muestras
x <- rep(0, n)

# Definimos el punto inicial
set.seed(123)
init <- sample(1:7, 1)
x[1] <- init
# Definimos los habitantes de cada estado

hab <- c(9, 16, 8, 5, 6, 8, 2)
curr_hab <- hab[x[1]]
curr_pos <- x[1]

set.seed(1234)
for (i in 1:n) {
    next_position <- curr_pos + sample(c(-1, 1), 1, prob = c(0.5, 0.5))
    # Check the next position is valid
    if (next_position > 0 & next_position < 8) {
        next_hab <- hab[next_position]
        # Check if the next position is better
        if (next_hab > curr_hab) {
            x[i] <- next_position
            curr_pos <- next_position
            curr_hab <- next_hab
        } else {
            u <- runif(1)
            if (u < next_hab/curr_hab) {
                x[i] <- next_position
                curr_pos <- next_position
                curr_hab <- next_hab
            } else {
                x[i] <- curr_pos
            }
        }
    } else {
        x[i] <- curr_pos
    }
}

# Graficamos las muestras
ggplot() +
    geom_line(aes(x = 1:n, y = x), color = "white", linetype = "solid") +
    geom_point(aes(x = 1:n, y = x), color = "white", size = 5) +
    coord_flip() +
    labs(x = "Muestra", y = "Estado") +
    scale_y_continuous(breaks = 1:7, labels = c("CDMX", "EdoMex", "Jalisco", 
                        "Nuevo León", "Puebla", "Veracruz", "Yucatán")) +
    dark_theme_gray() +
    theme(axis.text = element_text(size = 30),
        axis.title = element_text(size = 40),
        plot.title = element_text(size = 50),
        axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
```

- Podemos visualizar las muestras en un histograma:
```{r echo=TRUE}
ggplot() +
    geom_histogram(aes(x = x, y = ..density..), bins = 20, color = "white", fill = "white") +
    labs(x = "Estado", y = "Densidad") +
    scale_x_continuous(breaks = 1:7, labels = c("CDMX", "EdoMex", "Jalisco", "Nuevo León", "Puebla", "Veracruz", "Yucatán")) +
    dark_theme_gray() +
    theme(axis.text = element_text(size = 30),
        axis.title = element_text(size = 40),
        plot.title = element_text(size = 50),
        axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
```

- La verdadera distribución de probabilidad de los estados es:
```{r echo=FALSE}
density_states <- habitantes/sum(habitantes)

ggplot() +
    geom_bar(aes(x = estado, y = density_states), stat = "identity", color = "white", fill = "white") +
    labs(x = "Estado", y = "Densidad") +
    scale_x_discrete(labels = c("CDMX", "EdoMex", "Jalisco", "Nuevo León", "Puebla", "Veracruz", "Yucatán")) +
    dark_theme_gray() +
    theme(axis.text = element_text(size = 30),
        axis.title = element_text(size = 40),
        plot.title = element_text(size = 50),
        axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
```

:::

## Caminata aleatoria Metropolis-Hastings (MH) {.smaller}

- En nuestro ejemplo, cada ves que estamos en un estado $x_t$, la probabilidad de ir a otro estado $x_{t+1}$ depende de la cantidad de habitantes de cada estado (la densidad de probabilidad de cada estado). La regla que utilizamos para decidir si vamos a otro estado o no, se conoce como **regla de aceptación**.

- Solo nos podiamos mover a la izquierda o a la derecha y la probabilidad de ir a la izquierda o a la derecha era la misma y dependia del estado en el que estabamos. Este tipo de caminata aleatoria se conoce como **caminata aleatoria simétrica**. Ya que la distribución de probabilidad de ir a la izquierda es la misma que la distribución de probabilidad de ir a la derecha.

- EL último paso fue registrar el estado en el que estamos. Este paso se conoce como **muestreo**. En nuestro ejemplo, el muestreo se realizo cada vez que se genero un nuevo estado.

- Al final el muestreo se acerco a la distribución de probabilidad de los estados. Cuando realizamos estos pasos $n$ veces, obtenemos una secuencia de estados $x_1,\ldots,x_n$ que se conoce como **cadena de Markov**. En nuestro ejemplo, la cadena de Markov es la secuencia de estados que visitaremos.

- Normalmente se realizan varias cadenas de Markov. Cada una con un punto inicial diferente. Esto se conoce como **muestreo por cadenas de Markov Monte Carlo** (MCMC).

## Metroplis-Hastings {.smaller}

- El algoritmo de la caminata aleatoria Metropolis-Hastings (MH) es un algoritmo MCMC. Este algoritmo se puede utilizar para aproximar la posterior de $\theta$.

- De forma general realiza los siguientes pasos:
    1. Selecciona un punto inicial $\theta_0$.
    2. Genera un nuevo punto $\theta'$ utilizando una distribución de probabilidad $q(\theta'|\theta_t)$.
    3. Calcula la razón de aceptación:
$$
r= min \left( 1,\frac{P(x_1,\ldots,x_n|\theta')P(\theta')q(\theta_t|\theta')}{P(x_1,\ldots,x_n|\theta_t)P(\theta_t)q(\theta'|\theta_t)} \right)
$$
    4. Genera un número aleatorio $u$ entre 0 y 1.
    5. Si $u<r$, entonces $\theta_{t+1}=\theta'$.
    6. Si $u\geq r$, entonces $\theta_{t+1}=\theta_t$.
    7. Regresa al paso 2 y repite $n$ veces.

## Metroplis-Hastings {.smaller}

- De la expresión del punto 3, conocemos la verosimilitud $P(x_1,\ldots,x_n|\theta')$ y el prior $P(\theta')$. Pero, ¿cómo elegimos la distribución de probabilidad $q(\theta'|\theta_t)$?

- La distribución de probabilidad $q(\theta'|\theta_t)$ se conoce como **distribución de propuesta**. Esta distribución se puede elegir de varias formas. Las más comunes son:
    - **Distribución normal**: $q(\theta'|\theta_t)=N(\theta_t,\sigma^2)$.
    - **Distribución t**: $q(\theta'|\theta_t)=t(\theta_t,\sigma^2,\nu)$.
    - **Distribución uniforme**: $q(\theta'|\theta_t)=U(\theta_t-\sigma,\theta_t+\sigma)$.
    - **Distribución gamma**: $q(\theta'|\theta_t)=Gamma(\theta_t,\sigma^2)$.
    - **Distribución beta**: $q(\theta'|\theta_t)=Beta(\theta_t,\sigma^2)$.

- La distribución de propuesta se puede elegir de varias formas. La más común es utilizando una distribución normal con media $\theta_t$ y varianza $\sigma^2$. El algoritmo resultante se conoce como **algoritmo Metropolis**. Y elige la $\sigma^2$ de tal forma que la razón de aceptación sea cercana a 0.5, este periodo se conoce como **periodo de calentamiento**. 

- Existen diversos problemas cuando la distribución propuesta es una distribución normal. Por lo tanto, se recomienda utilizar una distribución no simétrica. Esto ya lo realiza el software que implementa el algoritmo Metropolis-Hastings.

## Metroplis-Hastings {.smaller}

- Veamos el ejemplo de la moneda con el algoritmo Metropolis. En este caso, la distribución de probabilidad $q(\theta'|\theta_t)$ es una distribución normal con media $\theta_t$ y varianza $\sigma^2$:
$$
q(\theta'|\theta_t)=N(\theta_t,\sigma^2)
$$

- Nuestro prior era una distribución Beta y nuestro modelo era una distribución binomial. Así que la tasa de aceptación es:
$$
\begin{align*}
&r= min \left( 1,\frac{P(x_1,\ldots,x_n|\theta')P(\theta')q(\theta_t|\theta')}{P(x_1,\ldots,x_n|\theta_t)P(\theta_t)q(\theta'|\theta_t)} \right)= \\
&min \left( 1,\frac{\theta'^{\sum x_i}(1-\theta')^{n-\sum x_i}\frac{\theta'^{\alpha-1}(1-\theta')^{\beta-1}}{B(\alpha,\beta)}N(\theta_t,\sigma^2)}{\theta_t^{\sum x_i}(1-\theta_t)^{n-\sum x_i}\frac{\theta_t^{\alpha-1}(1-\theta_t)^{\beta-1}}{B(\alpha,\beta)}N(\theta',\sigma^2)} \right)
\end{align*}
$$

## Metroplis-Hastings {.smaller}

- Veamos por partes como implementar el algorítmo Metropolis-Hastings en Python para nuestro ejemplo de la moneda.

- Para se usará el servicio de Google Colaboratory. Este servicio permite ejecutar código de Python en la nube. Para utilizarlo, es necesario tener una cuenta de Google.

- El link para acceder al servicio es: [https://colab.research.google.com/](https://colab.research.google.com/)

- El código se encuentra en el archivo [metropolis_MCMC.ipynb](https://drive.google.com/file/d/1pL5qiH-Cn-TOzQQh5IO6pbZB-C3g4bcC/view?usp=sharing)

## Otros algoritmos MCMC {.smaller}

- El algoritmo Metropolis-Hastings es una variante entre distintas que existen. Diversas modificaciones a la forma de proponer nuevos valores han llevado al desarrollo de variantes de la misma familia.

- Un ejemplo es el ***muestreo Halmintoniano***. Este algoritmo simula un modelo físico del movimiento de una partícula (valor del parámetro) para proponer nuevos valores. La regla de aceptación es la misma que en el algoritmo Metropolis-Hastings.

- El ***muestro NUTS*** (Not U-Turn Sampler) es una variante del muestreo Hamiltoniano. Permite una búsqueda más eficiente de los valores de los parámetros. Este algoritmo es el más eficiente de los tres.

- Cuando nuestro parámetro es discreto, podemos utilizar el ***muestreo de Gibbs***. Este algoritmo propone un nuevo valor para cada parámetro de forma secuencial, usando la distribución condicional de cada parámetro.

- La mayoria de los sofware de MCMC como Stan, Turing.jl, PyMC3 utilizan el muestreo NUTS. JAGS (Just Another Gibbs Sampler) utiliza el muestreo de Gibbs.

## Regresión lineal {.smaller}

::: {.nonincremental}
- Apliquemos lo que hemos visto hasta ahora a un ejemplo de regresión lineal.

- Simulemos datos con R.

```{r echo = FALSE}
# Definimos el número de muestras
n <- 100
# Definimos el vector de muestras
x <- seq(0, 10, length.out = n)
# Definimos el vector de parámetros
beta <- c(1, 2)
# Definimos el vector de errores
set.seed(12346)
e <- rnorm(n, 0, 4)
# Definimos el vector de muestras
y <- beta[1] + beta[2]*x + e

# Graficamos las muestras
library(ggplot2)
library(ggdark)
ggplot() +
    geom_point(aes(x = x, y = y), color = "white", size = 5) +
    labs(x = "x", y = "y") +
    dark_theme_gray() +
    theme(axis.text = element_text(size = 30),
        axis.title = element_text(size = 40),
        plot.title = element_text(size = 50))
```

- Para modelar de forma bayesiana tenemos que definir una distribución de probabilidad para los parámetros $\beta_0$ y $\beta_1$. Por ejemplo, podemos utilizar una distribución normal para cada parámetro:
$$
\begin{align*}
\beta_0 &\sim N(0,10) \\
\beta_1 &\sim N(0,10)
\end{align*}
$$

- También tenemos que definir una distribución de probabilidad para los errores. Por ejemplo, podemos utilizar una distribución normal:
$$
e_i \sim N(0,\sigma^2)
$$

- Finalmente, tenemos que definir una distribución de probabilidad para los datos. En este caso, podemos utilizar una distribución normal:
$$
y_i \sim N(\beta_0+\beta_1x_i,\sigma^2)
$$

- Donde $\sigma^2$ es la varianza de los errores.
:::

## Regresión lineal {.smaller}

::: {.nonincremental}
- Para resolver este problema, podemos utilizar el software Stan. Stan es un lenguaje de programación que permite especificar modelos estadísticos y que utiliza el muestreo NUTS para aproximar la posterior de los parámetros.

- Escribamos el modelo:
```{r echo =TRUE}
model <- "
data {
    int<lower=0> N;
    vector[N] x;
    vector[N] y;
}
parameters {
    real beta0;
    real beta1;
    real<lower=0> sigma;
}
model {
    beta0 ~ normal(0, 10);
    beta1 ~ normal(0, 10);
    sigma ~ normal(0, 10);

    y ~ normal(beta0 + beta1*x, sigma);
}
"
```

- El modelo se escribe en un archivo de texto con extensión `.stan`. En este caso, el archivo se llama `regresion.stan`.

- El modelo se compone de tres bloques:
    - **data**: En este bloque se definen los datos que se utilizarán en el modelo. En este caso, los datos son el vector `x` y el vector `y`.
    - **parameters**: En este bloque se definen los parámetros del modelo. En este caso, los parámetros son `beta0`, `beta1` y `sigma`.
    - **model**: En este bloque se definen las distribuciones de probabilidad de los parámetros y de los datos. En este caso, las distribuciones de probabilidad de los parámetros son normales y la distribución de probabilidad de los datos es normal.

:::

## Regresión lineal {.smaller}

::: {.nonincremental}
- Ahora, solo queda ejecutar el modelo en Stan. Para esto, utilizaremos el paquete `rstan` de R.

- Primero, tenemos que instalar el paquete `rstan`:
```{r echo = TRUE}
#install.packages("rstan")
```

- Después, tenemos que cargar el paquete `rstan` y create la estructura de los datos.
```{r echo = TRUE}
library(rstan)

# Definimos los datos
data <- list(N = n, x = x, y = y)
```

- Finalmente, tenemos que ejecutar el modelo en Stan:
```{r echo = TRUE}
# Ejecutamos el modelo
fit <- stan(model_code = model, data = data, iter = 500, chains = 4)
```

- El modelo se ejecuta con la función `stan`. Esta función recibe los siguientes argumentos:
    - **model_code**: El código del modelo.
    - **data**: Los datos del modelo.
    - **iter**: El número de iteraciones.
    - **chains**: El número de cadenas de Markov.
:::

## Regresión lineal {.smaller}

::: {.nonincremental}
- Una vez que se ejecuta el modelo, podemos ver un resumen de los parámetros:
```{r echo = TRUE}
print(fit, digits = 3, probs = c(0.025, 0.5, 0.975))
```

- Podemos ver las distribuciones de probabilidad de los parámetros:
```{r echo = TRUE}
plot(fit, pars = c("beta0", "beta1", "sigma"))
```

- Las cadenas de Markov de los parámetros:
```{r echo = TRUE}
traceplot(fit, pars = c("beta0"))
```
```{r echo = TRUE}
traceplot(fit, pars = c("beta1"))
```
```{r echo = TRUE}
traceplot(fit, pars = c("sigma"))
```

- Y las correlaciones entre los parámetros:
```{r echo = TRUE}
pairs(fit, pars = c("beta0", "beta1", "sigma"))
```
:::

## Regresión lineal {.smaller}

::: {.nonincremental}
- Podemos gráficar la distribución posterior y su intervalo de credibilidad al 95%:
```{r echo = TRUE}
library(bayesplot)
mcmc_areas(fit, pars = c("beta0", "beta1", "sigma"), prob = 0.95)
```

- Podemos gráficar diversas líneas de regresión:
```{r echo = TRUE}
# Definimos el número de muestras
beta_0_hat <- as.matrix(fit, pars = "beta0")
beta_1_hat <- as.matrix(fit, pars = "beta1")

n <- 100

beta_0_hat <- beta_0_hat[sample(1:nrow(beta_0_hat), n), ]
beta_1_hat <- beta_1_hat[sample(1:nrow(beta_1_hat), n), ]

y_hat <- matrix(0, nrow = n, ncol = length(x))

for (i in 1:n) {
    y_hat[i, ] <- beta_0_hat[i] + beta_1_hat[i]*x
}

# Graficamos las muestras

plot(NULL, xlim = c(0, 10), ylim = c(-10, 30), ann = FALSE, axes = FALSE)
for (i in 1:n) {
    lines(x, y_hat[i, ], col = "pink", lwd = 1, alpha = 0.45)
}

points(x, y, col = "black", pch = 20, cex = 2)


axis(1, at = seq(0, 10, 2), labels = seq(0, 10, 2))
axis(2, at = seq(-10, 30, 5), labels = seq(-10, 30, 5))

mtext("x", side = 1, line = 2.5, cex = 3)
mtext("y", side = 2, line = 2.5, cex = 3)

legend("topleft", legend = "y = beta0 + beta1*x", col = "pink", lwd = 2, cex = 2)
```
:::